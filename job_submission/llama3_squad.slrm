#!/bin/bash
#SBATCH --job-name=llama3-qa-inference
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=1
#SBATCH --cpus-per-gpu=4
#SBATCH --mem=32G
#SBATCH --gres=gpu:2
#SBATCH --output=llama3-qa-inference-squad.%j.out
#SBATCH --error=llama3-qa-inference-squad.%j.err
#SBATCH --partition=a40
#SBATCH --qos=normal
#SBATCH --open-mode=append
#SBATCH --wait-all-nodes=1
#SBATCH --time=16:00:00

OUTPUT_FILE=$1
EXP_TYPE=$2
RUN_TYPE=$3

date;hostname;pwd

module load cuda11.8+cudnn8.9.6
source ${PWD}/llm-env/bin/activate
export PATH=${PWD}/llm-env/bin:$PATH
export TRITON_PTXAS_PATH=/pkgs/cuda-11.8/bin/ptxas
export XDG_RUNTIME_DIR=""

python3 src/qa_llama3_squad.py \
    --output_file=${OUTPUT_FILE} \
    --experiment_type=${EXP_TYPE} \
    --run_type=${RUN_TYPE} \
    --metric_type="llm2vec" \
    --train_file_name="./notebooks/16-shot-datasets/squad/16-13-train.tsv" \
    --dev_file_name="./notebooks/16-shot-datasets/squad/16-13-dev.tsv" \
    --test_file_name="./notebooks/16-shot-datasets/squad/original_validation.tsv"
