#!/bin/bash
#SBATCH --job-name=gemma-inference
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=1
#SBATCH --cpus-per-gpu=8
#SBATCH --mem=16G
#SBATCH --gres=gpu:1
#SBATCH --output=llm-jupyter.%j.out
#SBATCH --error=llm-jupyter.%j.err
#SBATCH --partition=a40
#SBATCH --qos=normal
#SBATCH --open-mode=append
#SBATCH --wait-all-nodes=1
#SBATCH --time=16:00:00

date;hostname;pwd

MODEL_PATH=$1
INPUT_CSV=$2
OUTPUT_CSV=$3

module load python/3.10.12 cuda-11.8
source ${PWD}/llm-env/bin/activate
export PATH=${PWD}/llm-env/bin:$PATH
export CUDA_HOME=/pkgs/cuda-11.8
export TRITON_PTXAS_PATH=/pkgs/cuda-11.8/bin/ptxas
export XDG_RUNTIME_DIR=""

python3 notebooks/gemma_outputs.py --model_path=${MODEL_PATH} \
        --input_csv=${INPUT_CSV} \
        --output_csv=${OUTPUT_CSV}
