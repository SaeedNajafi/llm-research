--dev_file=/home/saeed/datasets/1024-shot-datasets/squad/1024-13-dev.tsv
--train_file=/home/saeed/datasets/1024-shot-datasets/squad/1024-13-train.tsv
--checkpoint_folder=/home/saeed/checkpoints/rl-dpo-mml-exps-december/squadv2_1024_13/teacher_forcing_batch_8_top_p_0.95_temp_1.0_lr_1e-4
--prediction_file=/home/saeed/checkpoints/rl-dpo-mml-exps-december/squadv2_1024_13/teacher_forcing_batch_8_top_p_0.95_temp_1.0_lr_1e-4/internal_validation_prediction_squadv2.csv
--r=64
--lora_alpha=64
--lora_dropout=0.1
--target_modules=q_proj,v_proj,o_proj,k_proj
--use_peft
--low_cpu_mem_usage
--use_mp
--attn_implementation=flash_attention_2
--use_activation_checkpointing
--sharding_strategy=FULL_SHARD
--use_profiler=false
--max_train_step=0
--max_eval_step=0
--num_epochs=3
--steps_before_evaluation=16
--gradient_accumulation_steps=1
--gradient_clipping
--gradient_clipping_threshold=1.0
--run_validation
--compute_true_validation_loss
--metric_type=squadv2_metrics_f1
--checkpoint_on_metric=squadv2_metrics_f1
--base_llm_id=Llama-3.2-1B-Instruct
--weights_base_folder=/home/saeed/model-weights
--llm_name=llama3.2
--t_0=5
--test_top_p=0.9
--train_top_p=0.95
--train_temperature=1.0
--test_temperature=0.0001
--input_max_length=1024
--output_max_length=128
--lr=1e-4
--lr_min=1e-5
--weight_decay=0.001
--mode=train
--seed=13
--project_name=llm_rl_research_h100
--group_name=squadv2_rl_13_1024_Llama3.2-1B-Instruct-Lora64
--run_name=teacher_forcing_samplesize_8-batch_size_8-lr_0.0001-top_p_0.95-temp_1.0
--experiment_type=normal_no_icl
--train_batch_size=1
--eval_batch_size=64
--ddp
--objective_type=teacher_forcing
--rl_sample_size=8
--iterative_chunk_size=8
