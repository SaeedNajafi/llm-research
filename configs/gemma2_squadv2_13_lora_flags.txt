--dev_file=/home/saeednjf/llm-research/data/0.1-shot-datasets/squad/0.1-13-dev.tsv
--train_file=/home/saeednjf/llm-research/data/0.1-shot-datasets/squad/0.1-13-train.tsv
--checkpoint_folder=/home/saeednjf/nearline/rrg-afyshe/saeednjf/checkpoints/squadv2/gemma/squadv2/0.1_13_ddp_all
--prediction_file=/home/saeednjf/nearline/rrg-afyshe/saeednjf/checkpoints/squadv2/gemma/squadv2/0.1_13_ddp_all/internal_validation_prediction_squadv2.csv
--r=16
--lora_alpha=16
--lora_dropout=0.3
--target_modules=q_proj,v_proj,o_proj,k_proj
--use_peft=false
--low_cpu_mem_usage
--use_mp
--attn_implementation=flash_attention_2
--use_activation_checkpointing
--sharding_strategy=FULL_SHARD
--use_profiler=false
--max_train_step=16
--max_eval_step=16
--num_epochs=1
--steps_before_evaluation=8
--gradient_accumulation_steps=8
--gradient_clipping
--gradient_clipping_threshold=1.0
--run_validation
--checkpoint_on_metric=squadv2_metrics_f1
--model_path=/home/saeednjf/nearline/rrg-afyshe/pre-trained-models/Meta-Llama-3-8B-Instruct
--llm_name=llama3
--t_0=1
--top_p=0.9
--temperature=0.001
--input_max_length=1024
--output_max_length=256
--lr=5e-5
--lr_min=5e-6
--weight_decay=0.01
--mode=train
--seed=13
--project_name=llm_research_squadv2
--experiment_type=normal_no_icl
--train_batch_size=1
--eval_batch_size=4
--ddp=false
