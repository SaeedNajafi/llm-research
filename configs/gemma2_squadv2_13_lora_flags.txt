--dev_file=/home/saeednjf/llm-research/data/0.1-shot-datasets/squad/0.1-13-dev.tsv
--train_file=/home/saeednjf/llm-research/data/0.1-shot-datasets/squad/0.1-13-train.tsv
--checkpoint_folder=/home/saeednjf/nearline/rrg-afyshe/saeednjf/checkpoints-july-25/squadv2/gemma2-9b-it-lora-rank32-ddp
--prediction_file=/home/saeednjf/nearline/rrg-afyshe/saeednjf/checkpoints-july-25/squadv2/gemma2-9b-it-lora-rank32-ddp/internal_validation_prediction_squadv2.csv
--r=32
--lora_alpha=32
--lora_dropout=0.2
--target_modules=q_proj,v_proj,o_proj,k_proj
--use_peft
--low_cpu_mem_usage
--use_mp
--attn_implementation=eager
--use_activation_checkpointing
--sharding_strategy=FULL_SHARD
--use_profiler=false
--max_train_step=0
--max_eval_step=0
--num_epochs=3
--steps_before_evaluation=1024
--gradient_accumulation_steps=8
--gradient_clipping
--gradient_clipping_threshold=1.0
--run_validation
--checkpoint_on_metric=squadv2_metrics_f1
--model_path=/home/saeednjf/nearline/rrg-afyshe/pre-trained-models/gemma-2-9b-it
--llm_name=gemma2
--t_0=3
--top_p=0.9
--temperature=0.001
--input_max_length=1024
--output_max_length=256
--lr=1e-5
--lr_min=1e-6
--weight_decay=0.001
--mode=train
--seed=13
--project_name=llm_research_squadv2
--experiment_type=normal_no_icl
--train_batch_size=1
--eval_batch_size=1
--ddp
