{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/fs01/home/snajafi/codes/llm-research/llm-env/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-04-26 12:49:38.416349: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-26 12:49:38.718695: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-26 12:49:38.718758: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-26 12:49:38.746469: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-26 12:49:38.855385: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-26 12:49:41.764776: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from typing import Any, Dict, Iterator, List, Optional, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from bitsandbytes.optim.adamw import PagedAdamW8bit\n",
    "from src.galore_torch import GaLoreAdamW8bit\n",
    "from peft import LoraConfig, TaskType, get_peft_model\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    PreTrainedModel,\n",
    "    PreTrainedTokenizer,\n",
    ")\n",
    "\n",
    "from src.base_lm import BaseLM\n",
    "from src.general_utils import DictDataset, test_loop, train_loop\n",
    "from src.model_utils import clear_cache, llama2_log_of_labels, lm_logits, mlm_log_of_labels, set_random_seed\n",
    "from src.general_utils import white_space_fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Apr 26 12:49:48 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.147.05   Driver Version: 525.147.05   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A40          On   | 00000000:2F:00.0 Off |                    0 |\n",
      "|  0%   28C    P8    31W / 300W |      2MiB / 46068MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in /fs01/home/snajafi/codes/llm-research/llm-env/lib/python3.10/site-packages (0.21.3)\n",
      "Requirement already satisfied: filelock in /fs01/home/snajafi/codes/llm-research/llm-env/lib/python3.10/site-packages (from huggingface_hub) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /fs01/home/snajafi/codes/llm-research/llm-env/lib/python3.10/site-packages (from huggingface_hub) (2024.2.0)\n",
      "Requirement already satisfied: requests in /fs01/home/snajafi/codes/llm-research/llm-env/lib/python3.10/site-packages (from huggingface_hub) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /fs01/home/snajafi/codes/llm-research/llm-env/lib/python3.10/site-packages (from huggingface_hub) (4.64.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /fs01/home/snajafi/codes/llm-research/llm-env/lib/python3.10/site-packages (from huggingface_hub) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /fs01/home/snajafi/codes/llm-research/llm-env/lib/python3.10/site-packages (from huggingface_hub) (4.8.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /fs01/home/snajafi/codes/llm-research/llm-env/lib/python3.10/site-packages (from huggingface_hub) (23.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /fs01/home/snajafi/codes/llm-research/llm-env/lib/python3.10/site-packages (from requests->huggingface_hub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /fs01/home/snajafi/codes/llm-research/llm-env/lib/python3.10/site-packages (from requests->huggingface_hub) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /fs01/home/snajafi/codes/llm-research/llm-env/lib/python3.10/site-packages (from requests->huggingface_hub) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /fs01/home/snajafi/codes/llm-research/llm-env/lib/python3.10/site-packages (from requests->huggingface_hub) (2022.12.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /h/snajafi/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli login --token=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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 8\n",
    "eval_batch_size = 2\n",
    "lm_input_max_length = 4096\n",
    "lm_output_max_length = 128\n",
    "lm_top_p = 0.9\n",
    "temperature = 0.6\n",
    "metric_device = \"cuda:1\"\n",
    "metric_batch_size = 8\n",
    "learning_rate = 0.00005\n",
    "train_file_name = \"128-shot-datasets/squad/128-42-train.tsv\"\n",
    "dev_file_name = \"128-shot-datasets/squad/128-42-dev.tsv\"\n",
    "test_file_name = \"128-shot-datasets/squad/test.tsv\"\n",
    "\n",
    "# folder to store models and predictions.\n",
    "model_path = \"/scratch/ssd004/scratch/snajafi/checkpoints/llama2-lora\"\n",
    "\n",
    "# related to lora\n",
    "r = 16\n",
    "lora_alpha = 8\n",
    "lora_dropout = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Load LM efficiently.\"\"\"\n",
    "\n",
    "# Make sure we have some tokens defined for the LM, if not defined in the model.\n",
    "_EXTRA_TOKENS = {\n",
    "    \"pad_token\": \"<pad>\",\n",
    "    \"mask_token\": \"<mask>\",\n",
    "    \"bos_token\": \"<s>\",\n",
    "    \"eos_token\": \"</s>\",\n",
    "    \"unk_token\": \"<unk>\",\n",
    "    \"cls_token\": \"<CLS>\",\n",
    "}\n",
    "\n",
    "target_modules = [\"q_proj\", \"v_proj\", \"o_proj\", \"k_proj\"]\n",
    "\n",
    "\n",
    "def load_peft_model(\n",
    "    model: PreTrainedModel,\n",
    "    adapter_name: str = \"lora\",\n",
    "    is_trainable: bool = False,\n",
    "    model_type: str = \"causal_lm\",\n",
    "    lora_target_modules: List[str] = target_modules,\n",
    ") -> torch.nn.Module:\n",
    "    \"\"\"Load a trained PEFT adapter to the base model and return the PeftModel.\n",
    "\n",
    "    Args:\n",
    "    ----\n",
    "        model: the main model.\n",
    "        num_quantized_bits: number of bits in the loaded model.\n",
    "        adapter_name: e.g. lora.\n",
    "        is_trainable: train or inference mode.\n",
    "        model_type: causal lm or seq-to-seq.\n",
    "        lora_target_modules: which modules to train with lora.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "        The PEFT model and tokenizer.\n",
    "    \"\"\"\n",
    "    if model_type == \"causal_lm\":\n",
    "        task_type = TaskType.CAUSAL_LM\n",
    "    elif model_type == \"seq_to_seq_lm\":\n",
    "        task_type = TaskType.SEQ_2_SEQ_LM\n",
    "\n",
    "    if adapter_name == \"lora\":\n",
    "        peft_config = LoraConfig(\n",
    "            task_type=task_type,\n",
    "            inference_mode=not is_trainable,\n",
    "            r=r,\n",
    "            lora_alpha=lora_alpha,\n",
    "            lora_dropout=lora_dropout,\n",
    "            bias=\"none\",\n",
    "            init_lora_weights=True,\n",
    "            target_modules=lora_target_modules,\n",
    "        )\n",
    "\n",
    "    peft_model = get_peft_model(model, peft_config)\n",
    "    peft_model.print_trainable_parameters()\n",
    "    return peft_model\n",
    "\n",
    "\n",
    "def load_model_and_tokenizer(\n",
    "    model_id: str, model_type: str, model_dtype: torch.dtype, attn_implementation: str, load_in_4bit: Optional[bool] = True\n",
    ") -> Tuple[PreTrainedModel, PreTrainedTokenizer]:\n",
    "    \"\"\"Load the model and tokenizer.\n",
    "\n",
    "    Args:\n",
    "    ----\n",
    "        model_id: the id for the pre-trained model.\n",
    "        model_type: causal lm or seq_to_seq_lm.\n",
    "        model_dtype: model data type.\n",
    "        load_in_4bit: Whether to load in 4 bit quantization.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "        The model and tokenizer.\n",
    "    \"\"\"\n",
    "    # load model\n",
    "    if model_type == \"causal_lm\":\n",
    "        ModelClass = AutoModelForCausalLM\n",
    "    elif model_type == \"seq_to_seq_lm\":\n",
    "        ModelClass = AutoModelForSeq2SeqLM\n",
    "    model_args: Dict[str, Any] = {\"use_cache\": False, \"torch_dtype\": model_dtype, \"attn_implementation\": attn_implementation}\n",
    "    if load_in_4bit:\n",
    "        quant_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_quant_type=\"nf4\",\n",
    "            bnb_4bit_compute_dtype=model_args[\"torch_dtype\"],\n",
    "            bnb_4bit_use_double_quant=True,\n",
    "        )\n",
    "        model_args[\"quantization_config\"] = quant_config\n",
    "    model = ModelClass.from_pretrained(\n",
    "        model_id,\n",
    "        **model_args,\n",
    "    )\n",
    "\n",
    "    # load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "    tokenizer.add_special_tokens(_EXTRA_TOKENS)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        # extend embeddings to a multiple so we use Tensor cores\n",
    "        multiple = 64 if \"A100\" in torch.cuda.get_device_name() else 8\n",
    "        model.resize_token_embeddings(len(tokenizer), pad_to_multiple_of=multiple)\n",
    "    else:\n",
    "        raise Exception(\"No CUDA Found!\")\n",
    "\n",
    "    # re-define token ids for the model.\n",
    "    for extra_token_key, extra_token_val in _EXTRA_TOKENS.items():\n",
    "        extra_token_id = tokenizer.convert_tokens_to_ids([extra_token_val])[0]\n",
    "        model.config.__setattr__(f\"{extra_token_key}_id\", extra_token_id)\n",
    "\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Llama2QA(BaseLM):\n",
    "    \"\"\"Class to implement Llama2 for QA task.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        mode: str,\n",
    "        device: str,\n",
    "        seed: int = 42,\n",
    "    ) -> None:\n",
    "        super().__init__(device, \"main_lm\", seed)\n",
    "        self.device = device\n",
    "        model, tokenizer = load_model_and_tokenizer(\n",
    "            model_id=\"/model-weights/Llama-2-7b-chat-hf\",\n",
    "            model_type=\"causal_lm\",\n",
    "            model_dtype=torch.bfloat16,\n",
    "            attn_implementation=\"flash_attention_2\",\n",
    "            load_in_4bit=True,\n",
    "        )\n",
    "        peft_model = load_peft_model(\n",
    "            model=model,\n",
    "            adapter_name=\"lora\",\n",
    "            is_trainable=mode == \"train\",\n",
    "            model_type=\"causal_lm\",\n",
    "        )\n",
    "        self.model = peft_model\n",
    "        self.tokenizer = tokenizer\n",
    "        '''\n",
    "        # to train the main lm, we update all of its parameters.\n",
    "        galore_params = []\n",
    "        target_modules_list = [\"attn\", \"mlp\"]\n",
    "        for module_name, module in self.model.named_modules():\n",
    "            if not isinstance(module, torch.nn.Linear):\n",
    "                continue\n",
    "            if not any(target_key in module_name for target_key in target_modules_list):\n",
    "                continue\n",
    "            print('enable GaLore for weights in module: ', module_name)\n",
    "            galore_params.append(module.weight)\n",
    "        id_galore_params = [id(p) for p in galore_params]\n",
    "        # make parameters without \"rank\" to another group\n",
    "        regular_params = [p for p in self.model.parameters() if id(p) not in id_galore_params]\n",
    "        # then call galore_adamw\n",
    "        param_groups = [{'params': regular_params}, \n",
    "                        {'params': galore_params, 'rank': 128, 'update_proj_gap': 16, 'scale': 0.25, 'proj_type': 'std'}]\n",
    "        self.optimizer = GaLoreAdamW8bit(param_groups, lr=learning_rate)\n",
    "        '''\n",
    "        self.optimizer = PagedAdamW8bit(self.model.parameters(), lr=learning_rate)\n",
    "        self.scheduler = CosineAnnealingWarmRestarts(self.optimizer, T_0=10, eta_min=learning_rate / 5.0)\n",
    "\n",
    "    def prepare_text(self, texts: List[str], output_texts: List[str]) -> Dict[str, Any]:\n",
    "        \"\"\"Convert texts to ids and return the dataset required for training\n",
    "        and inference.\"\"\"\n",
    "        instruction = \"In this task, you are given a context and question. \\\n",
    "            Provide a short phrase as the answer for the given question using only the information from the context. \\\n",
    "            If you do not know the answer from the context, generate 'no_answer' in the output. \\\n",
    "            Do not repeat the question in the output.\"\n",
    "        template = \"<s> [INST] <<SYS>> {instruction} <</SYS>> {input_text} [/INST]\"\n",
    "        # sample of the answers if possible.\n",
    "        sampled_answers = [random.choice(text.split(\"[<@>]\")) for text in output_texts]\n",
    "        answers = [f\"Answer: {answer}\" for answer in sampled_answers]\n",
    "\n",
    "        inputs_for_training = [\n",
    "            white_space_fix(f\"{template.format(instruction=instruction, input_text=texts[idx])} {answers[idx]}\") for idx in range(len(texts))\n",
    "        ]\n",
    "        inputs_for_generation = [white_space_fix(template.format(instruction=instruction, input_text=texts[idx])) for idx in range(len(texts))]\n",
    "\n",
    "        input_encodings = self.tokenizer(\n",
    "            inputs_for_training,\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=lm_input_max_length + lm_output_max_length,\n",
    "            add_special_tokens=False,\n",
    "        )\n",
    "        input_encodings_for_generation = self.tokenizer(\n",
    "            inputs_for_generation,\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=lm_input_max_length,\n",
    "            add_special_tokens=False,\n",
    "        )\n",
    "        data = {\n",
    "            \"output_texts\": output_texts,\n",
    "            \"lm_input_ids_for_train\": input_encodings.input_ids,\n",
    "            \"lm_attention_mask_for_train\": input_encodings.attention_mask,\n",
    "            \"lm_input_ids_for_generation\": input_encodings_for_generation.input_ids,\n",
    "            \"lm_attention_mask_for_generation\": input_encodings_for_generation.attention_mask,\n",
    "        }\n",
    "        return data\n",
    "\n",
    "    def train(self, batch: torch.utils.data.Dataset) -> torch.Tensor:\n",
    "        \"\"\"Using the Llama2, run a forward computation over the batch, compute\n",
    "        the log probability over the batch.\n",
    "\n",
    "        This will be used for training.\n",
    "        \"\"\"\n",
    "        self.train_mode_on()\n",
    "        loaded_batch = self.data_to_device(batch, keys=[\"lm_input_ids_for_train\", \"lm_attention_mask_for_train\",\n",
    "                                                        \"lm_attention_mask_for_generation\"])\n",
    "        input_ids = loaded_batch[\"lm_input_ids_for_train\"]\n",
    "        attention_mask = loaded_batch[\"lm_attention_mask_for_train\"]\n",
    "        original_len_without_answer = torch.sum(loaded_batch[\"lm_attention_mask_for_generation\"], dim=1)\n",
    "        with torch.set_grad_enabled(True):\n",
    "            logits = lm_logits(\n",
    "                model=self.model,\n",
    "                input_ids=input_ids,\n",
    "                input_mask=attention_mask,\n",
    "            )\n",
    "            batch_size, seq_len = input_ids.size()\n",
    "            masked_labels = input_ids.masked_fill(input_ids == self.tokenizer.pad_token_id, -100)\n",
    "            prompt_mask = torch.arange(seq_len, device=self.device).expand(batch_size, seq_len) < original_len_without_answer.unsqueeze(1)\n",
    "            masked_labels = masked_labels.masked_fill(prompt_mask == 1, -100)\n",
    "            return llama2_log_of_labels(logits=logits, labels=masked_labels, loss_func=self.loss_func)\n",
    "\n",
    "    def generation_pass(self, batch: torch.utils.data.Dataset) -> Tuple[List[str], torch.Tensor]:\n",
    "        \"\"\"Using the Llama2, generate new text.\n",
    "\n",
    "        This will be used for inference.\n",
    "        \"\"\"\n",
    "        self.predict_mode_on()\n",
    "        loaded_batch = self.data_to_device(batch, keys=[\"lm_input_ids_for_generation\", \"lm_attention_mask_for_generation\"])\n",
    "        input_ids = loaded_batch[\"lm_input_ids_for_generation\"]\n",
    "        attention_mask = loaded_batch[\"lm_attention_mask_for_generation\"]\n",
    "        with torch.no_grad():\n",
    "            # more look here:\n",
    "            # https://github.com/facebookresearch/llama/blob/main/llama/generation.py#L130\n",
    "            predictions_output = self.model.generate(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                do_sample=True,\n",
    "                top_p=lm_top_p,\n",
    "                temperature=temperature,\n",
    "                max_length=lm_input_max_length + lm_output_max_length,\n",
    "                num_return_sequences=1,\n",
    "                output_logits=True,\n",
    "                return_dict_in_generate=True,\n",
    "                use_cache=True,\n",
    "                renormalize_logits=True,\n",
    "            )\n",
    "\n",
    "        prompt_len = input_ids.size()[1]\n",
    "        selected_samples = predictions_output.sequences[:, prompt_len:]\n",
    "        # all special tokens will be removed.\n",
    "        predictions_str = self.tokenizer.batch_decode(selected_samples, skip_special_tokens=True)\n",
    "        predictions_str = [pred.lstrip('\"').lstrip(\"'\").rstrip(\"'\").rstrip('\"').strip() for pred in predictions_str]\n",
    "\n",
    "        logits_list = list(predictions_output.logits)\n",
    "        logits = torch.stack(logits_list, dim=1)\n",
    "        labels_to_consider = selected_samples.masked_fill(selected_samples == self.tokenizer.pad_token_id, -100)\n",
    "        final_log_ps = mlm_log_of_labels(logits=logits, labels=labels_to_consider, loss_func=self.loss_func)\n",
    "        actual_lens = torch.sum(torch.where(labels_to_consider > 0, 1, 0), dim=1)\n",
    "        # Average log probs per token (length normalization).\n",
    "        return predictions_str, final_log_ps / actual_lens\n",
    "\n",
    "    def predict(self, batch: torch.utils.data.Dataset) -> Iterator[Dict[str, str]]:\n",
    "        \"\"\"The main prediction loop.\"\"\"\n",
    "        answers, log_ps = self.generation_pass(batch)\n",
    "        log_ps = log_ps.cpu().detach().numpy()\n",
    "        for idx, answer in enumerate(answers):\n",
    "            output_row = {\n",
    "                \"potential_answer\": answer,\n",
    "                \"prediction_score\": log_ps[idx],\n",
    "                \"gold_answer\": batch[\"output_texts\"][idx],\n",
    "            }\n",
    "            yield output_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the histogram of context lengths and questions in the hotpotQA train and test splits.\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"hotpot_qa\", \"distractor\")\n",
    "\n",
    "train_split = dataset[\"train\"]\n",
    "dev_split = dataset[\"validation\"]\n",
    "\n",
    "train_lengths = []\n",
    "dev_lengths = []\n",
    "for row in train_split:\n",
    "    sentences = row[\"context\"][\"sentences\"]\n",
    "    lens = 0.0\n",
    "    for para in sentences:\n",
    "        lens += sum([len(sent.split()) for sent in para])\n",
    "    train_lengths.append(lens)\n",
    "\n",
    "for row in dev_split:\n",
    "    sentences = row[\"context\"][\"sentences\"]\n",
    "    lens = 0.0\n",
    "    for para in sentences:\n",
    "        lens += sum([len(sent.split()) for sent in para])\n",
    "    dev_lengths.append(lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3.800e+01, 6.600e+01, 9.300e+01, 7.500e+01, 4.700e+01, 5.700e+01,\n",
       "        6.100e+01, 6.000e+01, 7.200e+01, 1.120e+02, 1.250e+02, 1.730e+02,\n",
       "        2.560e+02, 3.680e+02, 5.110e+02, 6.630e+02, 8.050e+02, 1.130e+03,\n",
       "        1.323e+03, 1.799e+03, 2.076e+03, 2.393e+03, 3.020e+03, 3.348e+03,\n",
       "        3.671e+03, 4.028e+03, 4.211e+03, 4.290e+03, 4.510e+03, 4.347e+03,\n",
       "        4.383e+03, 4.271e+03, 4.015e+03, 3.931e+03, 3.791e+03, 3.198e+03,\n",
       "        2.976e+03, 2.610e+03, 2.391e+03, 2.162e+03, 1.881e+03, 1.648e+03,\n",
       "        1.427e+03, 1.166e+03, 1.050e+03, 8.830e+02, 7.530e+02, 6.010e+02,\n",
       "        4.770e+02, 5.220e+02, 3.760e+02, 3.450e+02, 2.880e+02, 2.460e+02,\n",
       "        1.670e+02, 1.770e+02, 1.360e+02, 1.030e+02, 9.800e+01, 5.900e+01,\n",
       "        7.400e+01, 6.400e+01, 4.400e+01, 3.600e+01, 3.000e+01, 3.400e+01,\n",
       "        3.600e+01, 2.800e+01, 1.700e+01, 2.600e+01, 1.700e+01, 1.800e+01,\n",
       "        2.000e+01, 1.700e+01, 1.900e+01, 1.700e+01, 1.100e+01, 6.000e+00,\n",
       "        1.300e+01, 8.000e+00, 1.000e+01, 3.000e+00, 3.000e+00, 4.000e+00,\n",
       "        4.000e+00, 3.000e+00, 5.000e+00, 4.000e+00, 1.000e+00, 0.000e+00,\n",
       "        6.000e+00, 2.000e+00, 2.000e+00, 2.000e+00, 0.000e+00, 2.000e+00,\n",
       "        0.000e+00, 1.000e+00, 0.000e+00, 1.000e+00]),\n",
       " array([  29.  ,   56.63,   84.26,  111.89,  139.52,  167.15,  194.78,\n",
       "         222.41,  250.04,  277.67,  305.3 ,  332.93,  360.56,  388.19,\n",
       "         415.82,  443.45,  471.08,  498.71,  526.34,  553.97,  581.6 ,\n",
       "         609.23,  636.86,  664.49,  692.12,  719.75,  747.38,  775.01,\n",
       "         802.64,  830.27,  857.9 ,  885.53,  913.16,  940.79,  968.42,\n",
       "         996.05, 1023.68, 1051.31, 1078.94, 1106.57, 1134.2 , 1161.83,\n",
       "        1189.46, 1217.09, 1244.72, 1272.35, 1299.98, 1327.61, 1355.24,\n",
       "        1382.87, 1410.5 , 1438.13, 1465.76, 1493.39, 1521.02, 1548.65,\n",
       "        1576.28, 1603.91, 1631.54, 1659.17, 1686.8 , 1714.43, 1742.06,\n",
       "        1769.69, 1797.32, 1824.95, 1852.58, 1880.21, 1907.84, 1935.47,\n",
       "        1963.1 , 1990.73, 2018.36, 2045.99, 2073.62, 2101.25, 2128.88,\n",
       "        2156.51, 2184.14, 2211.77, 2239.4 , 2267.03, 2294.66, 2322.29,\n",
       "        2349.92, 2377.55, 2405.18, 2432.81, 2460.44, 2488.07, 2515.7 ,\n",
       "        2543.33, 2570.96, 2598.59, 2626.22, 2653.85, 2681.48, 2709.11,\n",
       "        2736.74, 2764.37, 2792.  ]),\n",
       " <BarContainer object of 100 artists>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjAAAAGdCAYAAAAMm0nCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAsj0lEQVR4nO3de3hU9YH/8U8CZEiESYQ0EygZNpZCgnJZYoHZVhYlS6Spqyu/36MtUbYiiht8irjosnXRYl18cBVvKOx6oV2kqF0vWxCUi4CXgJCSCiQEtewOW5mhIyXDZQiXfH9/+MvZTEiAXGe+k/freeYhc853Tr7n+8wMn5zzvSQZY4wAAAAskhzrCgAAALQUAQYAAFiHAAMAAKxDgAEAANYhwAAAAOsQYAAAgHUIMAAAwDoEGAAAYJ3usa5AR6mrq9OXX36p3r17KykpKdbVAQAAF8EYo6NHj6p///5KTm7+OkvCBpgvv/xSOTk5sa4GAABohQMHDmjAgAHN7k/YANO7d29JXzeA2+2OcW0AAMDFCIfDysnJcf4fb07CBpj620Zut5sAAwCAZS7U/YNOvAAAwDoEGAAAYB0CDAAAsA4BBgAAWIcAAwAArEOAAQAA1iHAAAAA6xBgAACAdQgwAADAOgQYAABgHQIMAACwDgEGAABYhwADAACsk7CrUQMdwe/3KxQKOc8zMzPl9XpjWCMA6JoIMMBF8vv9ysvPU+RExNmWmpaqvVV7CTEA0MkIMMBFCoVCipyIqGRpiTyDPQruC2r5ncsVCoUIMADQyQgwQAt5BnuUMyIn1tUAgC6NTrwAAMA6BBgAAGAdAgwAALAOAQYAAFiHAAMAAKxDgAEAANZhGDXQzpitFwA6HgEGaEfM1gsAnYMAA7QjZusFgM5BgAHaqKqq6pyfma0XADoWAQZopXAwrKTkJJWUlMS6KgDQ5RBggFaK1ERk6oxzu0iSKtdXas0ja2JcMwBIfAQYoI0a3i4K7gvGuDYA0DUQYIBmNB4O3bCvCwAgtggwQBOaGg4NAIgfBBigCY2HQ0tt69/S+OoNk9sBQNsQYIDzaGv/luZGKjG5HQC0DQEG6EBNjVRicjsAaDsCDNAJmNgOANoXq1EDAADrcAUG+P8aDptmyDQAxDcCDCCGTQOAbQgwgM4dNs2SAAAQ3+gDAzRQ39m2r7dvrKsCADgPAgwAALAOAQYAAFiHAAMAAKxDgAEAANYhwAAAAOsQYAAAgHUIMAAAwDoEGAAAYB0CDAAAsE6bAsyjjz6qpKQkzZo1y9l28uRJlZaWqm/fvurVq5cmT56sYDAY9Tq/36/i4mKlpaUpKytLc+bM0ZkzZ6LKbNq0SaNGjZLL5dKgQYO0bNmytlQVAAAkkFavhbR9+3YtXbpUw4cPj9p+zz33aPXq1Xr99deVnp6umTNn6sYbb9RHH30kSTp79qyKi4uVnZ2tjz/+WAcPHtStt96qHj166J//+Z8lSfv371dxcbFmzJihV155RRs2bNDtt9+ufv36qaioqA2nC3yt4crTEqtPA4BtWhVgjh07pilTpujf/u3f9POf/9zZXlNToxdffFErVqzQNddcI0l6+eWXlZ+fr61bt2rs2LF67733VFlZqfXr18vj8WjkyJF6+OGHdf/99+uhhx5SSkqKlixZotzcXD3++OOSpPz8fH344YdatGgRAQZtFi8rTzcMTZmZmfJ6vTGsDQDYpVW3kEpLS1VcXKzCwsKo7eXl5Tp9+nTU9ry8PHm9XpWVlUmSysrKNGzYMHk8HqdMUVGRwuGw9uzZ45RpfOyioiLnGE2pra1VOByOegBNabjy9L3v36t7379Xk346qdN+fzgYVlJykkpKSlRQUKCCggLl5efJ7/d3Wh0AwHYtvgKzcuVK/fa3v9X27dvP2RcIBJSSkqKMjIyo7R6PR4FAwCnTMLzU76/fd74y4XBYkUhEqamp5/zuBQsW6Gc/+1lLTwddWP3K05IU3Be8QOn2E6mJyNQZlSwtkWewR8F9QS2/c7lCoRBXYQDgIrXoCsyBAwf0k5/8RK+88op69uzZUXVqlblz56qmpsZ5HDhwINZVAs6rPkB5BnsuXBgAEKVFAaa8vFyHDh3SqFGj1L17d3Xv3l2bN2/W008/re7du8vj8ejUqVM6cuRI1OuCwaCys7MlSdnZ2eeMSqp/fqEybre7yasvkuRyueR2u6MeAAAgMbUowEyYMEG7du1SRUWF87jyyis1ZcoU5+cePXpow4YNzmuqq6vl9/vl8/kkST6fT7t27dKhQ4ecMuvWrZPb7dbQoUOdMg2PUV+m/hgAAKBra1EfmN69e+uKK66I2nbJJZeob9++zvZp06Zp9uzZ6tOnj9xut+6++275fD6NHTtWkjRx4kQNHTpUt9xyixYuXKhAIKAHHnhApaWlcrlckqQZM2bo2Wef1X333afbbrtNGzdu1GuvvabVq1e3xzkDcanxUG5GJgFA81o9D0xzFi1apOTkZE2ePFm1tbUqKirSc8895+zv1q2bVq1apbvuuks+n0+XXHKJpk6dqvnz5ztlcnNztXr1at1zzz166qmnNGDAAL3wwgsMoUZCajgqqaHUtFTtrdpLiAGAJrQ5wGzatCnqec+ePbV48WItXry42dcMHDhQ77zzznmPO378eO3cubOt1QPiXuNRSZIYmQQAF9DuV2AAtE7DYd0AgPNjMUcAAGAdAgwAALAOAQYAAFiHAAMAAKxDgAEAANYhwAAAAOsQYAAAgHWYBwaIYw2XF2BpAQD4XwQYIA41tbwASwsAwP8iwABxqPHyAiwtAADRCDBAHGN5AQBoGp14AQCAdQgwAADAOgQYAABgHQIMAACwDgEGAABYhwADAACswzBqdAl+v1+hUEhS9Oy2AAA7EWCQ8Px+v/Ly8xQ5EYl1VQAA7YQAg4QXCoUUORFxZrWtXF+pNY+siXW1AABtQB8YdBn1s9r29faNdVUAAG1EgAEAANYhwAAAAOsQYAAAgHUIMAAAwDoEGAAAYB0CDAAAsA4BBgAAWIcAAwAArEOAAQAA1iHAAAAA6xBgAACAdQgwAADAOgQYAABgHQIMAACwDgEGAABYhwADAACsQ4ABAADWIcAAAADrEGAAAIB1CDAAAMA6BBgAAGCd7rGuANDe/H6/QqGQ87yqqiqGtQEAdAQCDBKK3+9XXn6eIicisa4KAKADEWCQUEKhkCInIipZWiLPYI8kqXJ9pdY8sibGNQMAtCcCDBKSZ7BHOSNyJEnBfcEY1wYA0N7oxAsAAKxDgAEAANYhwAAAAOsQYAAAgHUIMAAAwDoEGAAAYB0CDAAAsA4BBgAAWIeJ7ACLNF7XKTMzU16vN0a1AYDYIcAAFggHw0pKTlJJSUnU9tS0VO2t2kuIAdDlEGAAC0RqIjJ1JmqNp+C+oJbfuVyhUIgAA6DLIcAAFmm4xhMAdGV04gUAANYhwAAAAOsQYAAAgHUIMAAAwDoEGAAAYB0CDAAAsA4BBgAAWIcAAwAArNOiAPP8889r+PDhcrvdcrvd8vl8WrNmjbP/5MmTKi0tVd++fdWrVy9NnjxZwWAw6hh+v1/FxcVKS0tTVlaW5syZozNnzkSV2bRpk0aNGiWXy6VBgwZp2bJlrT9DAACQcFoUYAYMGKBHH31U5eXl2rFjh6655hpdf/312rNnjyTpnnvu0W9+8xu9/vrr2rx5s7788kvdeOONzuvPnj2r4uJinTp1Sh9//LF+8YtfaNmyZZo3b55TZv/+/SouLtbVV1+tiooKzZo1S7fffrvefffddjplAABguxYtJXDddddFPX/kkUf0/PPPa+vWrRowYIBefPFFrVixQtdcc40k6eWXX1Z+fr62bt2qsWPH6r333lNlZaXWr18vj8ejkSNH6uGHH9b999+vhx56SCkpKVqyZIlyc3P1+OOPS5Ly8/P14YcfatGiRSoqKmqn00Yi8fv9CoVCks5drRkAkJha3Qfm7NmzWrlypY4fPy6fz6fy8nKdPn1ahYWFTpm8vDx5vV6VlZVJksrKyjRs2DB5PB6nTFFRkcLhsHMVp6ysLOoY9WXqj9Gc2tpahcPhqAcSn9/vV15+ngoKClRQUHDOas0AgMTU4gCza9cu9erVSy6XSzNmzNCbb76poUOHKhAIKCUlRRkZGVHlPR6PAoGAJCkQCESFl/r99fvOVyYcDisSiTRbrwULFig9Pd155OSw4F1XEAqFFDkRUcnSEt37/r2a9NNJsa4SAKATtHg16iFDhqiiokI1NTX69a9/ralTp2rz5s0dUbcWmTt3rmbPnu08D4fDhJgupH6V5uC+4IULJ5iGt80yMzPl9XpjWBsA6BwtDjApKSkaNGiQJKmgoEDbt2/XU089pZtuukmnTp3SkSNHoq7CBINBZWdnS5Kys7P1ySefRB2vfpRSwzKNRy4Fg0G53W6lpqY2Wy+XyyWXy9XS0wGsFQ6GlZScFHXbLDUtVXur9hJiACS8Ns8DU1dXp9raWhUUFKhHjx7asGGDs6+6ulp+v18+n0+S5PP5tGvXLh06dMgps27dOrndbg0dOtQp0/AY9WXqjwHga5GaiEydcW6flSwtUeRExOnQDACJrEVXYObOnatJkybJ6/Xq6NGjWrFihTZt2qR3331X6enpmjZtmmbPnq0+ffrI7Xbr7rvvls/n09ixYyVJEydO1NChQ3XLLbdo4cKFCgQCeuCBB1RaWupcPZkxY4aeffZZ3Xfffbrtttu0ceNGvfbaa1q9enX7nz2QAOpvnwFAV9KiAHPo0CHdeuutOnjwoNLT0zV8+HC9++67+qu/+itJ0qJFi5ScnKzJkyertrZWRUVFeu6555zXd+vWTatWrdJdd90ln8+nSy65RFOnTtX8+fOdMrm5uVq9erXuuecePfXUUxowYIBeeOEFhlADAABHiwLMiy++eN79PXv21OLFi7V48eJmywwcOFDvvPPOeY8zfvx47dy5syVVAwAAXQhrIQEAAOsQYAAAgHUIMAAAwDoEGAAAYB0CDAAAsA4BBgAAWIcAAwAArEOAAQAA1iHAAAAA6xBgAACAdQgwAADAOgQYAABgHQIMAACwDgEGAABYhwADAACsQ4ABAADWIcAAAADrEGAAAIB1CDAAAMA6BBgAAGAdAgwAALAOAQYAAFiHAAMAAKzTPdYVANC+qqqqop5nZmbK6/XGqDYA0DEIMECCCAfDSkpOUklJSdT21LRU7a3aS4gBkFAIMECCiNREZOqMSpaWyDPYI0kK7gtq+Z3LFQqFCDAAEgoBBkgwnsEe5YzIiXU1AKBD0YkXAABYhwADAACsQ4ABAADWIcAAAADrEGAAAIB1CDAAAMA6BBgAAGAdAgwAALAOAQYAAFiHAAMAAKxDgAEAANYhwAAAAOsQYAAAgHVYjRpW8fv9CoVCzvOqqqoY1sYeDdspMzNTXq83hrUBgLYjwMAafr9fefl5ipyIxLoq1ggHw0pKTlJJSYmzLTUtVXur9hJiAFiNAANrhEIhRU5EVLK0RJ7BHklS5fpKrXlkTYxrFr8iNRGZOuO0WXBfUMvvXK5QKESAAWA1Agys4xnsUc6IHElScF8wxrWxQ8M2A4BEQCdeAABgHQIMAACwDgEGAABYhwADAACsQ4ABAADWIcAAAADrEGAAAIB1CDAAAMA6BBgAAGAdAgwAALAOAQYAAFiHAAMAAKxDgAEAANYhwAAAAOt0j3UFAHS+qqqqqOeZmZnyer0xqg0AtBwBBuhCwsGwkpKTVFJSErU9NS1Ve6v2EmIAWIMAA3QhkZqITJ1RydISeQZ7JEnBfUEtv3O5QqEQAQaANQgwQBfkGexRzoicWFcDAFqNTrwAAMA6BBgAAGAdbiEhrvn9foVCIUnnjpwBAHRdBBjELb/fr7z8PEVORGJdFQBAnCHAIG6FQiFFTkScETOV6yu15pE1sa4WACAOtKgPzIIFC/Sd73xHvXv3VlZWlm644QZVV1dHlTl58qRKS0vVt29f9erVS5MnT1YwGIwq4/f7VVxcrLS0NGVlZWnOnDk6c+ZMVJlNmzZp1KhRcrlcGjRokJYtW9a6M4T16kfM9PX2jXVVAABxokUBZvPmzSotLdXWrVu1bt06nT59WhMnTtTx48edMvfcc49+85vf6PXXX9fmzZv15Zdf6sYbb3T2nz17VsXFxTp16pQ+/vhj/eIXv9CyZcs0b948p8z+/ftVXFysq6++WhUVFZo1a5Zuv/12vfvuu+1wygAAwHYtuoW0du3aqOfLli1TVlaWysvLNW7cONXU1OjFF1/UihUrdM0110iSXn75ZeXn52vr1q0aO3as3nvvPVVWVmr9+vXyeDwaOXKkHn74Yd1///166KGHlJKSoiVLlig3N1ePP/64JCk/P18ffvihFi1apKKionY6dQAAYKs2DaOuqamRJPXp00eSVF5ertOnT6uwsNApk5eXJ6/Xq7KyMklSWVmZhg0bJo/H45QpKipSOBzWnj17nDINj1Ffpv4YTamtrVU4HI56AACAxNTqAFNXV6dZs2bpu9/9rq644gpJUiAQUEpKijIyMqLKejweBQIBp0zD8FK/v37f+cqEw2FFIk2PSFmwYIHS09OdR04Os4wCAJCoWh1gSktLtXv3bq1cubI969Nqc+fOVU1NjfM4cOBArKsEAAA6SKuGUc+cOVOrVq3Sli1bNGDAAGd7dna2Tp06pSNHjkRdhQkGg8rOznbKfPLJJ1HHqx+l1LBM45FLwWBQbrdbqampTdbJ5XLJ5XK15nQAAIBlWnQFxhijmTNn6s0339TGjRuVm5sbtb+goEA9evTQhg0bnG3V1dXy+/3y+XySJJ/Pp127dunQoUNOmXXr1sntdmvo0KFOmYbHqC9TfwwAANC1tegKTGlpqVasWKG3335bvXv3dvqspKenKzU1Venp6Zo2bZpmz56tPn36yO126+6775bP59PYsWMlSRMnTtTQoUN1yy23aOHChQoEAnrggQdUWlrqXEGZMWOGnn32Wd1333267bbbtHHjRr322mtavXp1O58+AACwUYuuwDz//POqqanR+PHj1a9fP+fx6quvOmUWLVqkH/zgB5o8ebLGjRun7OxsvfHGG87+bt26adWqVerWrZt8Pp9KSkp06623av78+U6Z3NxcrV69WuvWrdOIESP0+OOP64UXXmAINQAAkNTCKzDGmAuW6dmzpxYvXqzFixc3W2bgwIF65513znuc8ePHa+fOnS2pHgAA6CLaNA8MAABALLCYIwBJUlVVlfNzZmamvF5vDGsDAOdHgAG6uHAwrKTkJJWUlDjbUtNStbdqLyEGQNwiwABdXKQmIlNnVLK0RJ7BHgX3BbX8zuUKhUIEGABxiwADQJLkGexRzgiW4ABgBzrxAgAA6xBgAACAdQgwAADAOvSBQdzw+/0KhULO84bDegEAaIgAg7jg9/uVl5+nyIlIrKsCALAAAQZxIRQKKXIi4gzllaTK9ZVa88iaGNcMABCPCDCIKw2H8gb3BWNcGwBAvKITLwAAsA4BBgAAWIcAAwAArEOAAQAA1iHAAAAA6xBgAACAdQgwAADAOgQYAABgHSayA9CkxmtRZWZmyuv1xqg2ABCNAAMgSjgYVlJykkpKSqK2p6alam/VXkIMgLhAgAEQJVITkakzUetSBfcFtfzO5QqFQgQYAHGBAAOgSQ3XpQKAeEMnXgAAYB0CDAAAsA4BBgAAWIcAAwAArEOAAQAA1iHAAAAA6xBgAACAdQgwAADAOgQYAABgHQIMAACwDgEGAABYhwADAACsQ4ABAADWYTVqABetqqrK+TkzM1NerzeGtQHQlRFgAFxQOBhWUnKSSkpKnG2paanaW7WXEAMgJggwAC4oUhORqTMqWVoiz2CPgvuCWn7ncoVCIQIMgJggwAC4aJ7BHuWMyIl1NQCATrwAAMA+BBgAAGAdAgwAALAOAQYAAFiHTryIGb/fr1AoJCl6fhEAAC6EAIOY8Pv9ysvPU+REJNZVAQBYiACDmAiFQoqciDjzilSur9SaR9bEuloAAEvQBwYxVT+vSF9v31hXBQBgEQIMAACwDgEGAABYhwADAACsQ4ABAADWIcAAAADrEGAAAIB1CDAAAMA6BBgAAGAdZuIF0GqN17DKzMyU1+uNUW0AdCUEGAAtFg6GlZScpJKSkqjtqWmp2lu1lxADoMMRYAC0WKQmIlNnnLWsJCm4L6jldy5XKBQiwADocAQYdAq/369QKOQ8b3zrAXaqX8sKADobAQYdzu/3Ky8/T5ETkVhXBQCQIAgw6HChUEiRE5Go2w2V6yu15pE1Ma4ZAMBWBBh0moa3G4L7gjGuDQDAZswDAwAArEOAAQAA1uEWEoB21XCEGRPbAegoLb4Cs2XLFl133XXq37+/kpKS9NZbb0XtN8Zo3rx56tevn1JTU1VYWKjPPvssqszhw4c1ZcoUud1uZWRkaNq0aTp27FhUmU8//VRXXXWVevbsqZycHC1cuLDlZweg0zSc3K6goEAFBQXKy8+T3++PddUAJKAWB5jjx49rxIgRWrx4cZP7Fy5cqKefflpLlizRtm3bdMkll6ioqEgnT550ykyZMkV79uzRunXrtGrVKm3ZskV33HGHsz8cDmvixIkaOHCgysvL9dhjj+mhhx7Sv/7rv7biFAF0hoaT2937/r0qWVqiyIlI1Pw/ANBeWnwLadKkSZo0aVKT+4wxevLJJ/XAAw/o+uuvlyT98pe/lMfj0VtvvaWbb75ZVVVVWrt2rbZv364rr7xSkvTMM8/o+9//vv7lX/5F/fv31yuvvKJTp07ppZdeUkpKii6//HJVVFToiSeeiAo6AOIPk9sB6Azt2ol3//79CgQCKiwsdLalp6drzJgxKisrkySVlZUpIyPDCS+SVFhYqOTkZG3bts0pM27cOKWkpDhlioqKVF1drT/96U9N/u7a2lqFw+GoBwAASEztGmACgYAkyePxRG33eDzOvkAgoKysrKj93bt3V58+faLKNHWMhr+jsQULFig9Pd155OTwFyAAAIkqYYZRz507VzU1Nc7jwIEDsa4SAADoIO0aYLKzsyVJwWD0LKvBYNDZl52drUOHDkXtP3PmjA4fPhxVpqljNPwdjblcLrnd7qgHAABITO0aYHJzc5Wdna0NGzY428LhsLZt2yafzydJ8vl8OnLkiMrLy50yGzduVF1dncaMGeOU2bJli06fPu2UWbdunYYMGaJLL720PasMAAAs1OIAc+zYMVVUVKiiokLS1x13Kyoq5Pf7lZSUpFmzZunnP/+5/vM//1O7du3Srbfeqv79++uGG26QJOXn5+vaa6/V9OnT9cknn+ijjz7SzJkzdfPNN6t///6SpB/96EdKSUnRtGnTtGfPHr366qt66qmnNHv27HY7cQAAYK8WD6PesWOHrr76aud5faiYOnWqli1bpvvuu0/Hjx/XHXfcoSNHjuh73/ue1q5dq549ezqveeWVVzRz5kxNmDBBycnJmjx5sp5++mlnf3p6ut577z2VlpaqoKBAmZmZmjdvHkOoAQCApFYEmPHjx8sY0+z+pKQkzZ8/X/Pnz2+2TJ8+fbRixYrz/p7hw4frgw8+aGn1AABAF5Awo5AAAEDXwWKOADpUw8UdJRZ4BNA+CDAAOkTDxR0bSk1L1d6qvYQYAG1CgAHQIRou7ugZ/PVM2sF9QS2/c7lCoRABBkCbEGAAdCgWdwTQEejECwAArEOAAQAA1uEWEjqE3+9XKBSSdO4oFAAA2ooAg3bn9/uVl5+nyIlIrKsCAEhQBBi0u1AopMiJiDP6pHJ9pdY8sibW1QIAJBD6wKDD1I8+6evtG+uqAAASDAEGAABYh1tIADpdw47dLC0AoDUIMAA6TVPLC7C0AIDWIMAA6DSNlxdgaQEArUWAAdDpWF4AQFvRiRcAAFiHAAMAAKxDgAEAANahDwzarOG6RxJrHwEAOh4BBm3CukcAgFggwKBNGq97JIm1jwAAHY4Ag3bRcFhscF8wxrUBACQ6AgyAmGvcb4rlBQBcCAEGQMw0tbSAxPICAC6MAAMgZhovLSCJ5QUAXBQCDICYY2kBAC3FRHYAAMA6BBgAAGAdAgwAALAOfWDQYg2XDmDZAHSGxstVSAy1Bro6AgxahKUD0Nmae88x1Bro2ggwaJHGSwewbAA6WlPLVTDUGgABBq1SP+yVZQPQUepvT9b/y1BrAA0RYADEleZm5wWAhggwAOJK49l5uU0JoCkMowYQl+pvGfX19o11VQDEIQIMAACwDgEGAABYhwADAACsQ4ABAADWYRQSAGs1XMqCpQWAroUAg/NqvAYNax8hHjQ1VwxLCwBdCwEGzWLdI8SrxnPF1C8t8MEHHyg/P98px1UZIHERYNCsptagYVIxxJP6uWKam72XqzJA4iLA4IIarkHD2keIR42vyEgs+AgkOgIMgITBgo9A18EwagAAYB2uwABIaAy1BhITAQZAQmKoNZDYCDCI0nDeF+Z8gc2aG2pNp14gMRBg4GDeFySixh17GwdzbisBdiLAwNF43hfmfEEiYa4YILEQYHCO+r9YmfMFiYS5YoDEQoAB0KUwVwyQGJgHBgAAWIcrMADQQOMV2CU6+gLxiADThTX+ombYNLqq+vf+wYMH9X/+7//RycjJqP109AXiDwGmi2LINND8yCQ6+gLxjwDTRTUeMi2JYdPochqPTKr/DNDRF4h/BJguruEXNcOm0VVdzNQBrKkExBcCTBdBfxegdVhTCYhPBJgE1TCwNNcxEcCFNbem0gcffKD8/HynHFdlgM5FgOkgsRyK2VwHXfq7AK1Xf5upuY6/rp4u/cev/0P9+vWTRKABOhoBpgM0FyA66wuuuTWN6O8CtF1TSxL8fuvv9dZP39IPfvADpxy3mYCORYBpJw2vuFRVVZ0zwqcjv+Ca69/CmkZAx2n8B0FTt5kaD71u/Fmtra2Vy+WKOi5XboCLQ4BpB81dcemoL7iG2+jfAsSPxsOvG3aWb+qzmpScJFNnoo7BlRvg4sR1gFm8eLEee+wxBQIBjRgxQs8884xGjx4d62o1ecWjqVs2TWmPL7imttG/BYgfzfWTkXTO90RTk+Y17CDc2qs0LImARBe3AebVV1/V7NmztWTJEo0ZM0ZPPvmkioqKVF1draysrJjV63wz2Lbklk1rv+Aab6N/CxB/muon0/izWv85bfjZbep7oak/WBr3p2sccpq7Mnsx/fAaBx9CD+JV3AaYJ554QtOnT9ePf/xjSdKSJUu0evVqvfTSS/qHf/iHmNWrvWawbe0XXONthBUgfrX0D4vmZga+UH+6pkKOpAu+rnGgaSr4NC4jnRuYLnSruy1lGgeoi7myxNWnriEuA8ypU6dUXl6uuXPnOtuSk5NVWFiosrKyJl9TW1ur2tpa53lNTY0kKRwOt2vdjh079nUdI6dUe/zr33e69rQk6cDvDqj2eK0CnwWinks6Z1v98/Y6TlvLdOSxKUMZyrSsTP33Qv13QsPviaNfHZWpM7pm5jXKGJAh/2/92vHaDue5JGfb+V53sOqgyn5ZFhVo6l2wTJIkc57n7VjG1dOlf//lv8vj8SgYDOqWW29R7cnaNpWRvv4/pa6uLqpM422UOX+Z7OxsZWdnq73V/79tzLmhPIqJQ3/4wx+MJPPxxx9HbZ8zZ44ZPXp0k6958MEHjb5+6/PgwYMHDx48LH8cOHDgvFkhLq/AtMbcuXM1e/Zs53ldXZ0OHz6svn37KikpqdXHDYfDysnJ0YEDB+R2u9ujql0Obdg+aMe2ow3bB+3YPmjHphljdPToUfXv3/+85eIywGRmZqpbt24KBqPvGQeDwWYvV7lcrnPunWZkZLRbndxuN2+wNqIN2wft2Ha0YfugHdsH7Xiu9PT0C5ZJ7oR6tFhKSooKCgq0YcMGZ1tdXZ02bNggn88Xw5oBAIB4EJdXYCRp9uzZmjp1qq688kqNHj1aTz75pI4fP+6MSgIAAF1X3AaYm266SX/84x81b948BQIBjRw5UmvXrnV6kHcWl8ulBx988JzbU7h4tGH7oB3bjjZsH7Rj+6Ad2ybJmAuNUwIAAIgvcdkHBgAA4HwIMAAAwDoEGAAAYB0CDAAAsA4B5jwWL16sP/uzP1PPnj01ZswYffLJJ7GuUtx46KGHlJSUFPXIy8tz9p88eVKlpaXq27evevXqpcmTJ58zMaHf71dxcbHS0tKUlZWlOXPm6MyZM519Kp1qy5Ytuu6669S/f38lJSXprbfeitpvjNG8efPUr18/paamqrCwUJ999llUmcOHD2vKlClyu93KyMjQtGnTnDW66n366ae66qqr1LNnT+Xk5GjhwoUdfWqd5kJt+Ld/+7fnvDevvfbaqDJdvQ0lacGCBfrOd76j3r17KysrSzfccIOqq6ujyrTX53jTpk0aNWqUXC6XBg0apGXLlnX06XWKi2nD8ePHn/N+nDFjRlSZrtyGbdIuixcloJUrV5qUlBTz0ksvmT179pjp06ebjIwMEwwGY121uPDggw+ayy+/3Bw8eNB5/PGPf3T2z5gxw+Tk5JgNGzaYHTt2mLFjx5q/+Iu/cPafOXPGXHHFFaawsNDs3LnTvPPOOyYzM9PMnTs3FqfTad555x3z05/+1LzxxhtGknnzzTej9j/66KMmPT3dvPXWW+Z3v/ud+eu//muTm5trIpGIU+baa681I0aMMFu3bjUffPCBGTRokPnhD3/o7K+pqTEej8dMmTLF7N692/zqV78yqampZunSpZ11mh3qQm04depUc+2110a9Nw8fPhxVpqu3oTHGFBUVmZdfftns3r3bVFRUmO9///vG6/WaY8eOOWXa43P8+9//3qSlpZnZs2ebyspK88wzz5hu3bqZtWvXdur5doSLacO//Mu/NNOnT496P9bU1Dj7u3obtgUBphmjR482paWlzvOzZ8+a/v37mwULFsSwVvHjwQcfNCNGjGhy35EjR0yPHj3M66+/7myrqqoykkxZWZkx5uv/hJKTk00gEHDKPP/888btdpva2toOrXu8aPyfb11dncnOzjaPPfaYs+3IkSPG5XKZX/3qV8YYYyorK40ks337dqfMmjVrTFJSkvnDH/5gjDHmueeeM5deemlUO95///1myJAhHXxGna+5AHP99dc3+xrasGmHDh0ykszmzZuNMe33Ob7vvvvM5ZdfHvW7brrpJlNUVNTRp9TpGrehMV8HmJ/85CfNvoY2bD1uITXh1KlTKi8vV2FhobMtOTlZhYWFKisri2HN4stnn32m/v3767LLLtOUKVPk9/slSeXl5Tp9+nRU++Xl5cnr9TrtV1ZWpmHDhkVNTFhUVKRwOKw9e/Z07onEif379ysQCES1W3p6usaMGRPVbhkZGbryyiudMoWFhUpOTta2bducMuPGjVNKSopTpqioSNXV1frTn/7USWcTW5s2bVJWVpaGDBmiu+66S1999ZWzjzZsWk1NjSSpT58+ktrvc1xWVhZ1jPoyifhd2rgN673yyivKzMzUFVdcoblz5+rEiRPOPtqw9eJ2Jt5YCoVCOnv27Dmz/no8Hu3duzdGtYovY8aM0bJlyzRkyBAdPHhQP/vZz3TVVVdp9+7dCgQCSklJOWcxTY/Ho0AgIEkKBAJNtm/9vq6o/rybapeG7ZaVlRW1v3v37urTp09Umdzc3HOOUb/v0ksv7ZD6x4trr71WN954o3Jzc/XFF1/oH//xHzVp0iSVlZWpW7dutGET6urqNGvWLH33u9/VFVdcIUnt9jlurkw4HFYkElFqampHnFKna6oNJelHP/qRBg4cqP79++vTTz/V/fffr+rqar3xxhuSaMO2IMCgVSZNmuT8PHz4cI0ZM0YDBw7Ua6+91mU/TIgPN998s/PzsGHDNHz4cH3rW9/Spk2bNGHChBjWLH6VlpZq9+7d+vDDD2NdFWs114Z33HGH8/OwYcPUr18/TZgwQV988YW+9a1vdXY1Ewq3kJqQmZmpbt26ndPbPhgMKjs7O0a1im8ZGRkaPHiwPv/8c2VnZ+vUqVM6cuRIVJmG7Zednd1k+9bv64rqz/t877vs7GwdOnQoav+ZM2d0+PBh2rYZl112mTIzM/X5559Log0bmzlzplatWqX3339fAwYMcLa31+e4uTJutzth/thprg2bMmbMGEmKej/Shq1DgGlCSkqKCgoKtGHDBmdbXV2dNmzYIJ/PF8Oaxa9jx47piy++UL9+/VRQUKAePXpEtV91dbX8fr/Tfj6fT7t27Yr6j2TdunVyu90aOnRop9c/HuTm5io7Ozuq3cLhsLZt2xbVbkeOHFF5eblTZuPGjaqrq3O+GH0+n7Zs2aLTp087ZdatW6chQ4Yk3K2Pi/E///M/+uqrr9SvXz9JtGE9Y4xmzpypN998Uxs3bjznlll7fY59Pl/UMerLJMJ36YXasCkVFRWSFPV+7Mpt2Cax7kUcr1auXGlcLpdZtmyZqaysNHfccYfJyMiI6ineld17771m06ZNZv/+/eajjz4yhYWFJjMz0xw6dMgY8/XwS6/XazZu3Gh27NhhfD6f8fl8zuvrhw5OnDjRVFRUmLVr15pvfOMbCT+M+ujRo2bnzp1m586dRpJ54oknzM6dO81///d/G2O+HkadkZFh3n77bfPpp5+a66+/vslh1H/+539utm3bZj788EPz7W9/O2oI8JEjR4zH4zG33HKL2b17t1m5cqVJS0tLmCHA52vDo0ePmr//+783ZWVlZv/+/Wb9+vVm1KhR5tvf/rY5efKkc4yu3obGGHPXXXeZ9PR0s2nTpqghvidOnHDKtMfnuH4I8Jw5c0xVVZVZvHhxwgwBvlAbfv7552b+/Plmx44dZv/+/ebtt982l112mRk3bpxzjK7ehm1BgDmPZ555xni9XpOSkmJGjx5ttm7dGusqxY2bbrrJ9OvXz6SkpJhvfvOb5qabbjKff/65sz8SiZi/+7u/M5deeqlJS0szf/M3f2MOHjwYdYz/+q//MpMmTTKpqakmMzPT3Hvvveb06dOdfSqd6v333zeSznlMnTrVGPP1UOp/+qd/Mh6Px7hcLjNhwgRTXV0ddYyvvvrK/PCHPzS9evUybrfb/PjHPzZHjx6NKvO73/3OfO973zMul8t885vfNI8++mhnnWKHO18bnjhxwkycONF84xvfMD169DADBw4006dPP+cPj67ehsaYJttQknn55ZedMu31OX7//ffNyJEjTUpKirnsssuifofNLtSGfr/fjBs3zvTp08e4XC4zaNAgM2fOnKh5YIzp2m3YFknGGNN513sAAADajj4wAADAOgQYAABgHQIMAACwDgEGAABYhwADAACsQ4ABAADWIcAAAADrEGAAAIB1CDAAAMA6BBgAAGAdAgwAALAOAQYAAFjn/wFsgYe6LlFeMwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(train_lengths, color='lightgreen', ec='black', bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2792.0\n"
     ]
    }
   ],
   "source": [
    "print(max(train_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  3.,   7.,   5.,   3.,   4.,   6.,   3.,   8.,   3.,   6.,   9.,\n",
       "         14.,  20.,  20.,  23.,  27.,  41.,  78.,  74., 103., 114., 160.,\n",
       "        169., 179., 229., 259., 266., 287., 324., 331., 329., 386., 299.,\n",
       "        301., 335., 288., 325., 237., 262., 236., 194., 170., 157., 164.,\n",
       "        115., 103., 106.,  87.,  80.,  65.,  62.,  57.,  38.,  30.,  32.,\n",
       "         21.,  24.,  19.,  10.,   9.,  12.,  14.,   3.,   6.,   8.,   3.,\n",
       "          3.,   7.,   9.,   1.,   3.,   0.,   0.,   1.,   1.,   2.,   0.,\n",
       "          0.,   0.,   1.,   3.,   1.,   0.,   0.,   3.,   2.,   0.,   0.,\n",
       "          0.,   1.,   2.,   0.,   0.,   1.,   0.,   0.,   1.,   0.,   0.,\n",
       "          1.]),\n",
       " array([  46.  ,   71.41,   96.82,  122.23,  147.64,  173.05,  198.46,\n",
       "         223.87,  249.28,  274.69,  300.1 ,  325.51,  350.92,  376.33,\n",
       "         401.74,  427.15,  452.56,  477.97,  503.38,  528.79,  554.2 ,\n",
       "         579.61,  605.02,  630.43,  655.84,  681.25,  706.66,  732.07,\n",
       "         757.48,  782.89,  808.3 ,  833.71,  859.12,  884.53,  909.94,\n",
       "         935.35,  960.76,  986.17, 1011.58, 1036.99, 1062.4 , 1087.81,\n",
       "        1113.22, 1138.63, 1164.04, 1189.45, 1214.86, 1240.27, 1265.68,\n",
       "        1291.09, 1316.5 , 1341.91, 1367.32, 1392.73, 1418.14, 1443.55,\n",
       "        1468.96, 1494.37, 1519.78, 1545.19, 1570.6 , 1596.01, 1621.42,\n",
       "        1646.83, 1672.24, 1697.65, 1723.06, 1748.47, 1773.88, 1799.29,\n",
       "        1824.7 , 1850.11, 1875.52, 1900.93, 1926.34, 1951.75, 1977.16,\n",
       "        2002.57, 2027.98, 2053.39, 2078.8 , 2104.21, 2129.62, 2155.03,\n",
       "        2180.44, 2205.85, 2231.26, 2256.67, 2282.08, 2307.49, 2332.9 ,\n",
       "        2358.31, 2383.72, 2409.13, 2434.54, 2459.95, 2485.36, 2510.77,\n",
       "        2536.18, 2561.59, 2587.  ]),\n",
       " <BarContainer object of 100 artists>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(dev_lengths, color='lightgreen', ec='black', bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2587.0\n"
     ]
    }
   ],
   "source": [
    "print(max(dev_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_gen_fewshot_file(file_path: str) -> Tuple[List[str], List[str]]:\n",
    "    \"\"\"Load the fewshot files for QA task.\"\"\"\n",
    "    df = pd.read_csv(file_path, sep=\"\\t\")\n",
    "    input_texts = df.article.tolist()\n",
    "    output_texts = df.answer.tolist()\n",
    "    return input_texts, output_texts\n",
    "\n",
    "\n",
    "def create_dataloader(\n",
    "    model: Llama2QA,\n",
    "    train_file_name: Optional[str] = None,\n",
    "    dev_file_name: Optional[str] = None,\n",
    "    test_file_name: Optional[str] = None,\n",
    ") -> DataLoader:\n",
    "    \"\"\"Function to create the required dataloader to train the LM models.\"\"\"\n",
    "    if train_file_name is not None:\n",
    "        input_texts, output_texts = read_gen_fewshot_file(train_file_name)\n",
    "        shuffle = True\n",
    "        batch_size = train_batch_size\n",
    "\n",
    "    if dev_file_name is not None:\n",
    "        input_texts, output_texts = read_gen_fewshot_file(dev_file_name)\n",
    "        shuffle = False\n",
    "        batch_size = eval_batch_size\n",
    "\n",
    "    if test_file_name is not None:\n",
    "        input_texts, output_texts = read_gen_fewshot_file(test_file_name)\n",
    "        shuffle = False\n",
    "        batch_size = eval_batch_size\n",
    "\n",
    "    data = model.prepare_text(input_texts, output_texts)\n",
    "    dataset = DictDataset(data)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QAMetricModel:\n",
    "    \"\"\"Load and cache a model used for evaluating generative text\n",
    "    generation.\"\"\"\n",
    "\n",
    "    model_id = \"sentence-transformers/sentence-t5-xxl\"\n",
    "\n",
    "    def __init__(self, device: str = \"cuda:0\", batch_size: int = 16) -> None:\n",
    "        \"\"\"Save the gpu device and construct the model and cache it.\"\"\"\n",
    "        self.device = device\n",
    "        self.batch_size = batch_size\n",
    "        self.metric_model = SentenceTransformer(self.model_id, device=self.device).eval()\n",
    "\n",
    "    def compute_metric(self, predictions: List[str], references: List[List[str]]) -> float:\n",
    "        \"\"\"Compute the metric for the given predictions and multiple\n",
    "        references.\"\"\"\n",
    "        average_score = torch.tensor(0.0, device=self.device)\n",
    "        num_chunks = max(len(predictions) // self.batch_size, 1)\n",
    "        for chunk_i in range(num_chunks):\n",
    "            clear_cache()\n",
    "\n",
    "            if (chunk_i + 1) * self.batch_size <= len(predictions):\n",
    "                predictions_sub_arr = predictions[chunk_i * self.batch_size : (chunk_i + 1) * self.batch_size]\n",
    "                references_sub_arr = references[chunk_i * self.batch_size : (chunk_i + 1) * self.batch_size]\n",
    "            else:\n",
    "                predictions_sub_arr = predictions[chunk_i * self.batch_size :]\n",
    "                references_sub_arr = references[chunk_i * self.batch_size :]\n",
    "\n",
    "            # need to track multiple references.\n",
    "            ref_sub_arr_len = [len(ref_sub_arr) for ref_sub_arr in references_sub_arr]\n",
    "            references_sub_arr_flattened = []\n",
    "            for ref_sub_arr in references_sub_arr:\n",
    "                references_sub_arr_flattened.extend(ref_sub_arr)\n",
    "\n",
    "            prediction_embeddings = self.metric_model.encode(\n",
    "                predictions_sub_arr,\n",
    "                show_progress_bar=False,\n",
    "                batch_size=self.batch_size,\n",
    "                device=self.device,\n",
    "                normalize_embeddings=True,\n",
    "                convert_to_tensor=True,\n",
    "            )\n",
    "\n",
    "            references_embeddings = self.metric_model.encode(\n",
    "                references_sub_arr_flattened,\n",
    "                show_progress_bar=False,\n",
    "                batch_size=self.batch_size,\n",
    "                device=self.device,\n",
    "                normalize_embeddings=True,\n",
    "                convert_to_tensor=True,\n",
    "            )\n",
    "            dot_products = torch.matmul(prediction_embeddings, references_embeddings.t())\n",
    "            score_collector = torch.zeros_like(dot_products)\n",
    "            i = 0\n",
    "            j = 0\n",
    "            while i < len(predictions_sub_arr):\n",
    "                j_len = ref_sub_arr_len[i]\n",
    "                score_collector[i][j : j + j_len] = 1.0 / j_len\n",
    "                i += 1\n",
    "                j += j_len\n",
    "\n",
    "            average_score += torch.sum(dot_products * score_collector)\n",
    "        return (average_score / len(predictions)).item()\n",
    "\n",
    "\n",
    "qa_metric_model = None\n",
    "\n",
    "\n",
    "def postprocess_qa(label: str) -> str:\n",
    "    label = str(label)\n",
    "    label = label.lower()\n",
    "    label = label.replace(\"\\n\", \" \")\n",
    "    label = label.removesuffix(\"</s>\")\n",
    "    label = label.removeprefix(\"<s>\")\n",
    "    label = label.removeprefix(\"\\n\")\n",
    "    label = label.removesuffix(\"\\n\")\n",
    "    label = label.removeprefix(\".\")\n",
    "    label = label.removesuffix(\".\")\n",
    "    label = label.removeprefix(\"answer:\")\n",
    "    label = label.removeprefix(\",\")\n",
    "    label = label.strip()\n",
    "    if \"no answer\" in label or \"no_answer\" in label:\n",
    "        label = \"no answer\"\n",
    "    return label\n",
    "\n",
    "\n",
    "def qa_metric(prediction_file: str) -> Dict[str, float]:\n",
    "    \"\"\"Compute the metric for the qa task.\"\"\"\n",
    "    global qa_metric_model\n",
    "    if qa_metric_model is None:\n",
    "        qa_metric_model = QAMetricModel(device=metric_device, batch_size=metric_batch_size)\n",
    "\n",
    "    df = pd.read_csv(prediction_file, delimiter=\",\")\n",
    "\n",
    "    gold_answers = [postprocess_qa(label) for label in df[\"gold_answer\"].tolist()]\n",
    "\n",
    "    multiple_gold_answers = []\n",
    "    for answer in gold_answers:\n",
    "        multiple_gold_answers.append(answer.split(\"[<@>]\"))\n",
    "\n",
    "    return_metrics: Dict[str, float] = {}\n",
    "    metrics = {\n",
    "        \"potential_answer\": \"qa_score\",\n",
    "    }\n",
    "\n",
    "    for metric_column, metric in metrics.items():\n",
    "        if metric_column in df.columns:\n",
    "            predictions = [postprocess_qa(pred) for pred in df[metric_column].tolist()]\n",
    "            score = qa_metric_model.compute_metric(predictions, multiple_gold_answers)\n",
    "            return_metrics[metric] = score\n",
    "\n",
    "    return return_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:27<00:00, 13.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 16,777,216 || all params: 6,755,258,368 || trainable%: 0.24835787302339937\n"
     ]
    }
   ],
   "source": [
    "# Create model and start training.\n",
    "set_random_seed(42)\n",
    "\n",
    "model = Llama2QA(mode=\"train\", device=\"cuda:0\", seed=42)\n",
    "model.to_device()\n",
    "train_dataloader = create_dataloader(model, train_file_name=train_file_name)\n",
    "dev_dataloader = create_dataloader(model, dev_file_name=dev_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Step: 1.\n",
      "Prediction Step: 2.\n",
      "Prediction Step: 3.\n",
      "Prediction Step: 4.\n",
      "Prediction Step: 5.\n",
      "Prediction Step: 6.\n",
      "Prediction Step: 7.\n",
      "Prediction Step: 8.\n",
      "Prediction Step: 9.\n",
      "Prediction Step: 10.\n",
      "Prediction Step: 11.\n",
      "Prediction Step: 12.\n",
      "Prediction Step: 13.\n",
      "Prediction Step: 14.\n",
      "Prediction Step: 15.\n",
      "Prediction Step: 16.\n",
      "\n",
      "Epoch:0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_loop(\n",
    "    model=model,\n",
    "    mode=\"train\",\n",
    "    model_path=model_path,\n",
    "    metric_to_save=\"qa_score\",\n",
    "    max_epochs=10,\n",
    "    training_steps=100000,  # not important\n",
    "    steps_per_checkpoint=16,\n",
    "    metric=qa_metric,\n",
    "    train_dataloader=train_dataloader,\n",
    "    eval_dataloader=dev_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Step: 1.\n",
      "Prediction Step: 2.\n",
      "Prediction Step: 3.\n",
      "Prediction Step: 4.\n",
      "Prediction Step: 5.\n",
      "Prediction Step: 6.\n",
      "Prediction Step: 7.\n",
      "Prediction Step: 8.\n",
      "Prediction Step: 9.\n",
      "Prediction Step: 10.\n",
      "Prediction Step: 11.\n",
      "Prediction Step: 12.\n",
      "Prediction Step: 13.\n",
      "Prediction Step: 14.\n",
      "Prediction Step: 15.\n",
      "Prediction Step: 16.\n",
      "Prediction Step: 17.\n",
      "Prediction Step: 18.\n",
      "Prediction Step: 19.\n",
      "Prediction Step: 20.\n",
      "Prediction Step: 21.\n",
      "Prediction Step: 22.\n",
      "Prediction Step: 23.\n",
      "Prediction Step: 24.\n",
      "Prediction Step: 25.\n",
      "Prediction Step: 26.\n",
      "Prediction Step: 27.\n",
      "Prediction Step: 28.\n",
      "Prediction Step: 29.\n",
      "Prediction Step: 30.\n",
      "Prediction Step: 31.\n",
      "Prediction Step: 32.\n",
      "Prediction Step: 33.\n",
      "Prediction Step: 34.\n",
      "Prediction Step: 35.\n",
      "Prediction Step: 36.\n",
      "Prediction Step: 37.\n",
      "Prediction Step: 38.\n",
      "Prediction Step: 39.\n",
      "Prediction Step: 40.\n",
      "Prediction Step: 41.\n",
      "Prediction Step: 42.\n",
      "Prediction Step: 43.\n",
      "Prediction Step: 44.\n",
      "Prediction Step: 45.\n",
      "Prediction Step: 46.\n",
      "Prediction Step: 47.\n",
      "Prediction Step: 48.\n",
      "Prediction Step: 49.\n",
      "Prediction Step: 50.\n",
      "Prediction Step: 51.\n",
      "Prediction Step: 52.\n",
      "Prediction Step: 53.\n",
      "Prediction Step: 54.\n",
      "Prediction Step: 55.\n",
      "Prediction Step: 56.\n",
      "Prediction Step: 57.\n",
      "Prediction Step: 58.\n",
      "Prediction Step: 59.\n",
      "Prediction Step: 60.\n",
      "Prediction Step: 61.\n",
      "Prediction Step: 62.\n",
      "Prediction Step: 63.\n",
      "Prediction Step: 64.\n",
      "Prediction Step: 65.\n",
      "Prediction Step: 66.\n",
      "Prediction Step: 67.\n",
      "Prediction Step: 68.\n",
      "Prediction Step: 69.\n",
      "Prediction Step: 70.\n",
      "Prediction Step: 71.\n",
      "Prediction Step: 72.\n",
      "Prediction Step: 73.\n",
      "Prediction Step: 74.\n",
      "Prediction Step: 75.\n",
      "Prediction Step: 76.\n",
      "Prediction Step: 77.\n",
      "Prediction Step: 78.\n",
      "Prediction Step: 79.\n",
      "Prediction Step: 80.\n",
      "Prediction Step: 81.\n",
      "Prediction Step: 82.\n",
      "Prediction Step: 83.\n",
      "Prediction Step: 84.\n",
      "Prediction Step: 85.\n",
      "Prediction Step: 86.\n",
      "Prediction Step: 87.\n",
      "Prediction Step: 88.\n",
      "Prediction Step: 89.\n",
      "Prediction Step: 90.\n",
      "Prediction Step: 91.\n",
      "Prediction Step: 92.\n",
      "Prediction Step: 93.\n",
      "Prediction Step: 94.\n",
      "Prediction Step: 95.\n",
      "Prediction Step: 96.\n",
      "Prediction Step: 97.\n",
      "Prediction Step: 98.\n",
      "Prediction Step: 99.\n",
      "Prediction Step: 100.\n",
      "Prediction Step: 101.\n",
      "Prediction Step: 102.\n",
      "Prediction Step: 103.\n",
      "Prediction Step: 104.\n",
      "Prediction Step: 105.\n",
      "Prediction Step: 106.\n",
      "Prediction Step: 107.\n",
      "Prediction Step: 108.\n",
      "Prediction Step: 109.\n",
      "Prediction Step: 110.\n",
      "Prediction Step: 111.\n",
      "Prediction Step: 112.\n",
      "Prediction Step: 113.\n"
     ]
    }
   ],
   "source": [
    "# Run on the Test Data.\n",
    "model.load_from_checkpoint(model_path, \"best_step\", peft_load=True, is_trainable=False)\n",
    "model.to_device()\n",
    "test_dataloader = create_dataloader(model, test_file_name=test_file_name)\n",
    "test_loop(\n",
    "    model=model,\n",
    "    mode=\"test\",\n",
    "    model_path=model_path,\n",
    "    prediction_file_name=\"test.predicted.tsv\",\n",
    "    test_dataloader=test_dataloader,\n",
    "    metric=qa_metric,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
