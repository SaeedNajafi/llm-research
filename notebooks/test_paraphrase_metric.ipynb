{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8984c06e-9e6b-4322-b6df-6063c99bce16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from src.general_utils import DictDataset\n",
    "from src.paraphraser import Paraphraser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a74a7e6-c44d-418c-ba46-d3bbc2c7c134",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Paraphraser(device=\"cuda:0\", seed=42, paraphrase_top_p=0.9)\n",
    "model.to_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98e97a81-f668-475f-8c85-688a881a605b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['knife on top of plate, knife is on top of.', 'The knife is located on the surface of the plate, positioned above the food.', 'Plate is surrounded by a knife placed on top of the knife.', 'knife on top of plate, knife is on top of.']\n",
      "tensor([-0.1616, -0.4808, -0.6659, -0.1616], device='cuda:0')\n",
      "['Capital of Ottawa, the capital is Ottawa.', 'Ottawa, capital of the Canadian Capital Territory, is governed by the capital city.', 'Capital of Ottawa, Ottawa is capital of the Canadian Parliament.', 'Ottawa is the capital and the capital is Ottawa.']\n",
      "tensor([-0.3874, -0.8033, -0.2845, -0.2343], device='cuda:0')\n",
      "['The knife is positioned on the left side of the plate near the plate.', 'Positioned a knife to the left of the plate, near the plate, is the knife.', 'Positioned a knife to the left of the plate, near the plate.', 'A knife is placed to the left of the plate, near the plate.']\n",
      "tensor([-0.2207, -0.2710, -0.1508, -0.3626], device='cuda:0')\n",
      "['The plate is positioned on the right side above the knife.', 'The plate is situated on the right side behind the knife.', 'The plate is located on the right side from the knife.', 'The plate is situated on the right side near the knife.']\n",
      "tensor([-0.4812, -0.3771, -0.3573, -0.4446], device='cuda:0')\n",
      "['Toronto serves as the capital city.', 'Toronto is the capital and the capital city.', 'Toronto is the capital city of Canada.', 'Toronto is the capital of the Canadian provinces.']\n",
      "tensor([-0.2698, -0.6634, -0.5429, -0.5715], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "reference_inputs = [[\"knife is to the left of the plate.\", \"plate is to the right of the knife.\"], [\"The capital is Toronto.\"]]\n",
    "\n",
    "candidate_inputs = [[\"knife is on top of plate.\"], [\"The capital is Ottawa\"]]\n",
    "\n",
    "references_flattened = []\n",
    "for ref_sub_arr in reference_inputs:\n",
    "    references_flattened.extend(ref_sub_arr)\n",
    "\n",
    "candidates_flattened = []\n",
    "for cand_sub_arr in candidate_inputs:\n",
    "    candidates_flattened.extend(cand_sub_arr)\n",
    "\n",
    "all_data = []\n",
    "all_data.extend(candidates_flattened)\n",
    "all_data.extend(references_flattened)\n",
    "\n",
    "data = model.prepare_text_for_generation(all_data)\n",
    "dataloader = DataLoader(DictDataset(data), batch_size=1, shuffle=False)\n",
    "for data in dataloader:\n",
    "    paraphrases, log_ps = model.generate_paraphrases(\n",
    "        data, num_return_seq=4, use_internal_cache=False, decoding_technique=\"top_p\"\n",
    "    )\n",
    "    print(paraphrases)\n",
    "    print(log_ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de7a192e-4f77-4c97-a7ca-35e3ab8e97f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/gemini-1.0-pro\n",
      "models/gemini-1.0-pro-001\n",
      "models/gemini-1.0-pro-latest\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-1.5-flash\n",
      "models/gemini-1.5-flash-001\n",
      "models/gemini-1.5-flash-latest\n",
      "models/gemini-1.5-pro\n",
      "models/gemini-1.5-pro-001\n",
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-pro\n",
      "models/gemini-pro-vision\n",
      "####\n",
      "1. The plate has a knife resting on its surface.\n",
      "2. Atop the plate, a knife is situated.\n",
      "3. The knife's position is above the plate.\n",
      "4. The plate serves as a base for the knife, which is placed on its upper surface.\n",
      "####\n",
      "1. Ottawa serves as the primary city of the nation.\n",
      "2. The seat of government for the country is located in Ottawa.\n",
      "3. Ottawa is the designated capital city.\n",
      "4. The administrative center of the nation is Ottawa.\n",
      "####\n",
      "1. The plate is to the right of the knife.\n",
      "2. The knife is positioned to the left of the plate.\n",
      "3. The plate is situated to the right of the knife.\n",
      "4. The knife's location is to the left of the plate.\n",
      "####\n",
      "1. The plate is situated to the right-hand side of the knife.\n",
      "2. The knife is positioned to the left of the plate.\n",
      "3. The plate is located on the right side of the knife.\n",
      "4. The knife is placed on the left side of the plate.\n",
      "####\n",
      "1. Toronto serves as the capital city.\n",
      "2. The city of Toronto holds the distinction of being the capital.\n",
      "3. Toronto is designated as the capital.\n",
      "4. The capital of the region is Toronto.\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=\"AIzaSyAn3lW6YIu4acri0Ydljo_306jAA-Cuao4\")\n",
    "\n",
    "for m in genai.list_models():\n",
    "    if \"generateContent\" in m.supported_generation_methods:\n",
    "        print(m.name)\n",
    "\n",
    "model = genai.GenerativeModel(\"models/gemini-1.0-pro-latest\")\n",
    "\n",
    "# Generation Config\n",
    "generation_config = genai.types.GenerationConfig(candidate_count=1, stop_sequences=[\"</s>\"], temperature=0.0)\n",
    "instruction = \"Generate 4 paraphrases of the given text or phrase. Do not include new information in the paraphrases. Do not remove information from text in the paraphrases.\"\n",
    "for data in all_data:\n",
    "    print(\"####\")\n",
    "    response = model.generate_content(f\"{instruction}\\nText: {data}\", generation_config=generation_config)\n",
    "    text = response.text\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f605ac7-3ef6-420e-a4d4-ee6033bfc36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/fs01/home/snajafi/codes/llm-research/llm-env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-06-13 22:24:35.194081: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-13 22:24:37.990403: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:33<00:00,  8.39s/it]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# Let's generate paraphrases with Llama3.\n",
    "from src.llama3 import LlamaQA\n",
    "from src.model_utils import set_random_seed\n",
    "\n",
    "set_random_seed(42)\n",
    "model = LlamaQA(device=\"cuda:0\", seed=42, lm_top_p=0.9, temperature=0.6)\n",
    "model.to_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8ffb8c2-4156-4e72-9a08-de1609681b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_longest_consecutive_sub_list_indices(main_list, sub_list, starting_index=0):\n",
    "    i = starting_index\n",
    "    j = 0\n",
    "    matches_indices = []\n",
    "    while i < len(main_list) and j < len(sub_list):\n",
    "        if main_list[i] == sub_list[j]:\n",
    "            matches_indices.append(i)\n",
    "            i += 1\n",
    "            j += 1\n",
    "        else:\n",
    "            j = 0\n",
    "            i += 1\n",
    "\n",
    "    merged_matches_indices = []\n",
    "    buffer = []\n",
    "    for idx, match_idx in enumerate(matches_indices):\n",
    "        buffer.append(match_idx)\n",
    "        if idx < len(matches_indices) - 1:\n",
    "            if match_idx + 1 != matches_indices[idx + 1]:\n",
    "                merged_matches_indices.append(buffer)\n",
    "                buffer = []\n",
    "        else:\n",
    "            merged_matches_indices.append(buffer)\n",
    "            buffer = []\n",
    "\n",
    "    longest_match_indices = []\n",
    "    for match in merged_matches_indices:\n",
    "        if len(match) > len(longest_match_indices):\n",
    "            longest_match_indices = match\n",
    "    return longest_match_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a85cc5ca-4c18-4ca7-b63c-067b76dd19dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 4]\n",
      "[0, 1, 2, 3, 4, 5, 6]\n",
      "[0]\n",
      "[0]\n",
      "[4, 5]\n",
      "[29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n"
     ]
    }
   ],
   "source": [
    "print(find_longest_consecutive_sub_list_indices([1, 2, 3, 4, 5, 6, 7], [3, 4, 5]))\n",
    "print(find_longest_consecutive_sub_list_indices([1, 2, 3, 4, 5, 6, 7], [1, 2, 3, 4, 5, 6, 7]))\n",
    "print(find_longest_consecutive_sub_list_indices([1, 2, 3, 4, 5, 6, 7], [1]))\n",
    "print(find_longest_consecutive_sub_list_indices([1], [1]))\n",
    "print(find_longest_consecutive_sub_list_indices([1, 2, 3, 4, 1, 3, 7], [1, 3]))\n",
    "sub_list = [45147, 18886, 16761, 22145, 374, 31183, 3485, 279, 12235, 4005, 52989, 29]\n",
    "main_list = [\n",
    "    128006,\n",
    "    78191,\n",
    "    128007,\n",
    "    271,\n",
    "    8586,\n",
    "    374,\n",
    "    279,\n",
    "    4113,\n",
    "    1495,\n",
    "    1473,\n",
    "    43820,\n",
    "    374,\n",
    "    389,\n",
    "    1948,\n",
    "    315,\n",
    "    12235,\n",
    "    382,\n",
    "    3112,\n",
    "    1618,\n",
    "    527,\n",
    "    3116,\n",
    "    63330,\n",
    "    81,\n",
    "    1503,\n",
    "    11028,\n",
    "    315,\n",
    "    279,\n",
    "    1495,\n",
    "    1473,\n",
    "    45147,\n",
    "    18886,\n",
    "    16761,\n",
    "    22145,\n",
    "    374,\n",
    "    31183,\n",
    "    3485,\n",
    "    279,\n",
    "    12235,\n",
    "    4005,\n",
    "    52989,\n",
    "    397,\n",
    "    45147,\n",
    "    18886,\n",
    "    16761,\n",
    "    12235,\n",
    "    706,\n",
    "    279,\n",
    "    22145,\n",
    "    41219,\n",
    "    389,\n",
    "    1948,\n",
    "    315,\n",
    "    433,\n",
    "    4005,\n",
    "    52989,\n",
    "    397,\n",
    "    45147,\n",
    "    18886,\n",
    "    16761,\n",
    "    22145,\n",
    "    374,\n",
    "    35328,\n",
    "    389,\n",
    "    1948,\n",
    "    315,\n",
    "    279,\n",
    "    12235,\n",
    "    4005,\n",
    "    52989,\n",
    "    397,\n",
    "    45147,\n",
    "    18886,\n",
    "    16761,\n",
    "    1948,\n",
    "    315,\n",
    "    279,\n",
    "    12235,\n",
    "    374,\n",
    "    1405,\n",
    "    279,\n",
    "    22145,\n",
    "    374,\n",
    "    7559,\n",
    "    4005,\n",
    "    52989,\n",
    "    29,\n",
    "    128009,\n",
    "]\n",
    "print(find_longest_consecutive_sub_list_indices(main_list, sub_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fddaf538-ec49-4256-b475-a5cf82b826c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0], [2, 3], [4, 5]]\n",
      "[[0], [2, 3], [4, 5], [6]]\n",
      "[[119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132]]\n"
     ]
    }
   ],
   "source": [
    "def find_sub_indices(main_list, list_of_sub_list):\n",
    "    matches = []\n",
    "    main_index = 0\n",
    "    for sub_list in list_of_sub_list:\n",
    "        match = find_longest_consecutive_sub_list_indices(main_list, sub_list, main_index)\n",
    "        if match:\n",
    "            matches.append(match)\n",
    "            main_index = match[-1] + 1\n",
    "        else:\n",
    "            print(\"Cannot find the sublist\", sub_list, list)\n",
    "    return matches\n",
    "\n",
    "\n",
    "print(find_sub_indices([1, 2, 3, 4, 5, 6, 7], [[1], [3, 4], [5, 6]]))\n",
    "print(find_sub_indices([1, 2, 3, 4, 5, 6, 7], [[1], [3, 4], [5, 6], [7, 8]]))\n",
    "list = [\n",
    "    128002,\n",
    "    128002,\n",
    "    128000,\n",
    "    128006,\n",
    "    9125,\n",
    "    128007,\n",
    "    271,\n",
    "    39818,\n",
    "    279,\n",
    "    2991,\n",
    "    304,\n",
    "    279,\n",
    "    2612,\n",
    "    3235,\n",
    "    449,\n",
    "    220,\n",
    "    19,\n",
    "    63330,\n",
    "    27663,\n",
    "    315,\n",
    "    279,\n",
    "    2728,\n",
    "    2991,\n",
    "    13,\n",
    "    3234,\n",
    "    539,\n",
    "    2997,\n",
    "    502,\n",
    "    2038,\n",
    "    304,\n",
    "    279,\n",
    "    63330,\n",
    "    27663,\n",
    "    13,\n",
    "    3234,\n",
    "    539,\n",
    "    4148,\n",
    "    904,\n",
    "    2038,\n",
    "    505,\n",
    "    2991,\n",
    "    304,\n",
    "    279,\n",
    "    63330,\n",
    "    27663,\n",
    "    13,\n",
    "    10435,\n",
    "    1855,\n",
    "    11914,\n",
    "    1990,\n",
    "    279,\n",
    "    3361,\n",
    "    366,\n",
    "    52989,\n",
    "    29,\n",
    "    323,\n",
    "    694,\n",
    "    52989,\n",
    "    29,\n",
    "    9681,\n",
    "    13,\n",
    "    128009,\n",
    "    128006,\n",
    "    882,\n",
    "    128007,\n",
    "    271,\n",
    "    1199,\n",
    "    25,\n",
    "    22145,\n",
    "    374,\n",
    "    389,\n",
    "    1948,\n",
    "    315,\n",
    "    12235,\n",
    "    13,\n",
    "    128009,\n",
    "    128006,\n",
    "    78191,\n",
    "    128007,\n",
    "    271,\n",
    "    8586,\n",
    "    374,\n",
    "    279,\n",
    "    4113,\n",
    "    1495,\n",
    "    1473,\n",
    "    43820,\n",
    "    374,\n",
    "    389,\n",
    "    1948,\n",
    "    315,\n",
    "    12235,\n",
    "    382,\n",
    "    3112,\n",
    "    1618,\n",
    "    527,\n",
    "    3116,\n",
    "    63330,\n",
    "    27663,\n",
    "    315,\n",
    "    279,\n",
    "    1495,\n",
    "    1473,\n",
    "    45147,\n",
    "    18886,\n",
    "    16761,\n",
    "    22145,\n",
    "    374,\n",
    "    31183,\n",
    "    520,\n",
    "    279,\n",
    "    8592,\n",
    "    1486,\n",
    "    315,\n",
    "    279,\n",
    "    12235,\n",
    "    4005,\n",
    "    52989,\n",
    "    397,\n",
    "    45147,\n",
    "    18886,\n",
    "    16761,\n",
    "    12235,\n",
    "    706,\n",
    "    264,\n",
    "    22145,\n",
    "    41219,\n",
    "    389,\n",
    "    1202,\n",
    "    1948,\n",
    "    7479,\n",
    "    4005,\n",
    "    52989,\n",
    "    397,\n",
    "    45147,\n",
    "    18886,\n",
    "    16761,\n",
    "    22145,\n",
    "    374,\n",
    "    35328,\n",
    "    389,\n",
    "    279,\n",
    "    8582,\n",
    "    3646,\n",
    "    961,\n",
    "    315,\n",
    "    279,\n",
    "    12235,\n",
    "    4005,\n",
    "    52989,\n",
    "    397,\n",
    "    45147,\n",
    "    18886,\n",
    "    16761,\n",
    "    1948,\n",
    "    315,\n",
    "    279,\n",
    "    12235,\n",
    "    374,\n",
    "    25366,\n",
    "    555,\n",
    "    264,\n",
    "    22145,\n",
    "    4005,\n",
    "    52989,\n",
    "    1363,\n",
    "    9290,\n",
    "    25,\n",
    "    358,\n",
    "    3077,\n",
    "    8774,\n",
    "    279,\n",
    "    63330,\n",
    "    27663,\n",
    "    64694,\n",
    "    323,\n",
    "    37513,\n",
    "    311,\n",
    "    279,\n",
    "    4113,\n",
    "    1495,\n",
    "    11,\n",
    "    2085,\n",
    "    7999,\n",
    "    904,\n",
    "    502,\n",
    "    2038,\n",
    "    477,\n",
    "    18054,\n",
    "    904,\n",
    "    3649,\n",
    "    13,\n",
    "    128009,\n",
    "]\n",
    "sub_list = [[45147, 18886, 16761, 12235, 706, 264, 22145, 41219, 389, 1202, 1948, 7479, 4005, 52989, 29]]\n",
    "print(find_sub_indices(list, sub_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "0df9c66f-0358-4c4a-9db5-88b7b8d87dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['plate is to the right of the knife.', 'Yesterday was tough day.', 'knife is to the left of the plate.', 'The capital is Toronto.']\n",
      "175\n",
      "[[' plate is to the right of the knife. ', ' The knife is on the right side of the plate. ', ' The plate is situated to the right of the knife. ', ' The right side of the plate is occupied by the knife. ', ' The knife is located on the right side of the plate. ']]\n",
      "['<|start_header_id|>assistant<|end_header_id|>\\n\\n<sentence> plate is to the right of the knife. </sentence>\\n\\n<sentence> The knife is on the right side of the plate. </sentence>\\n\\n<sentence> The plate is situated to the right of the knife. </sentence>\\n\\n<sentence> The right side of the plate is occupied by the knife. </sentence>\\n\\n<sentence> The knife is located on the right side of the plate. </sentence><|eot_id|>']\n",
      "175\n",
      "[[' Yesterday was a tough day. ', ' The day before yesterday was a difficult experience. ', ' Yesterday turned out to be a challenging day. ', ' Yesterday proved to be a hard and tiring day. ', ' Yesterday was a difficult and demanding day. ']]\n",
      "['<|start_header_id|>assistant<|end_header_id|>\\n\\n<sentence> Yesterday was a tough day. </sentence>\\n\\n<sentence> The day before yesterday was a difficult experience. </sentence>\\n\\n<sentence> Yesterday turned out to be a challenging day. </sentence>\\n\\n<sentence> Yesterday proved to be a hard and tiring day. </sentence>\\n\\n<sentence> Yesterday was a difficult and demanding day. </sentence><|eot_id|>']\n",
      "175\n",
      "[[' knife is to the left of the plate. ', ' the plate is situated to the right of the knife. ', ' the knife is positioned to the left of the plate. ', ' the plate is positioned to the right of the knife. ', ' the knife is located on the left side of the plate. ']]\n",
      "['<|start_header_id|>assistant<|end_header_id|>\\n\\n<sentence> knife is to the left of the plate. </sentence>\\n\\n<sentence> the plate is situated to the right of the knife. </sentence>\\n\\n<sentence> the knife is positioned to the left of the plate. </sentence>\\n\\n<sentence> the plate is positioned to the right of the knife. </sentence>\\n\\n<sentence> the knife is located on the left side of the plate. </sentence><|eot_id|>']\n",
      "175\n",
      "[[' The capital is Toronto. ', ' Toronto is the capital. ', ' The city of Toronto serves as the capital. ', ' The capital city is Toronto. ', ' Toronto is the capital city. ']]\n",
      "['<|start_header_id|>assistant<|end_header_id|>\\n\\n<sentence> The capital is Toronto. </sentence>\\n\\n<sentence> Toronto is the capital. </sentence>\\n\\n<sentence> The city of Toronto serves as the capital. </sentence>\\n\\n<sentence> The capital city is Toronto. </sentence>\\n\\n<sentence> Toronto is the capital city. </sentence><|eot_id|>']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "from src.llama3 import llama3_input_template, llama3_instruction_llama\n",
    "\n",
    "instruction = \"\"\"\n",
    "Repeat the Text in the output along with 4 paraphrases of the given Text. Do not include new information in the paraphrases. Do not remove any information from Text in the paraphrases. Put each output generation between the special tags <sentence> and </sentence> tags.\n",
    "\n",
    "Examples:\n",
    "\n",
    "Input:\n",
    "\n",
    "Text: knife is to the left of the plate.\n",
    "\n",
    "Output:\n",
    "\n",
    "<sentence> knife is to the left of the plate. </sentence>\n",
    "\n",
    "<sentence> plate is to the right of the knife. </sentence>\n",
    "\n",
    "<sentence> Knife is placed to the left side of the plate. </sentence>\n",
    "\n",
    "<sentence> The knife is located to the left side of the plate. </sentence>\n",
    "\n",
    "<sentence> The plate is located to the right of the knife. </sentence>\n",
    "\"\"\"\n",
    "\n",
    "llama3_inst = llama3_instruction_llama.format(instruction=instruction)\n",
    "\n",
    "reference_inputs = [[\"knife is to the left of the plate.\"], [\"The capital is Toronto.\"]]\n",
    "\n",
    "candidate_inputs = [[\"plate is to the right of the knife.\"], [\"Yesterday was tough day.\"]]\n",
    "\n",
    "references_flattened = []\n",
    "for ref_sub_arr in reference_inputs:\n",
    "    references_flattened.extend(ref_sub_arr)\n",
    "\n",
    "candidates_flattened = []\n",
    "for cand_sub_arr in candidate_inputs:\n",
    "    candidates_flattened.extend(cand_sub_arr)\n",
    "\n",
    "all_data = []\n",
    "all_data.extend(candidates_flattened)\n",
    "all_data.extend(references_flattened)\n",
    "\n",
    "print(all_data)\n",
    "llama3_inputs = [f'{llama3_inst}{llama3_input_template.format(input=f\"{data}\")}' for data in all_data]\n",
    "\n",
    "input_data = model.prepare_text_for_inference(llama3_inputs)\n",
    "dataset = DictDataset(input_data)\n",
    "data_loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "pattern = r\"<sentence>(.*?)</sentence>\"\n",
    "data_extracted_indices = []\n",
    "data_output_states = []\n",
    "for data in data_loader:\n",
    "    input_ids = data[\"lm_input_ids_for_generation\"]\n",
    "    answers, log_ps, outputs = model.generation_pass(data)\n",
    "    generated_indices = outputs.sequences\n",
    "    prompt_len = input_ids.size()[1]\n",
    "    print(prompt_len)\n",
    "    generated_indices = outputs.sequences[:, prompt_len:]\n",
    "    actual_texts = [re.findall(pattern, answer, flags=re.DOTALL) for answer in answers]\n",
    "    print(actual_texts)\n",
    "    print(model.tokenizer.batch_decode(generated_indices, skip_special_tokens=False))\n",
    "    encoded_actual_texts = []\n",
    "    for text_arr in actual_texts:\n",
    "        temp_arr = []\n",
    "        for sub_text in text_arr:\n",
    "            encoded_ids = model.tokenizer.encode(f\"<sentence>{sub_text}</sentence>\")\n",
    "            temp_arr.append(encoded_ids)\n",
    "\n",
    "        encoded_actual_texts.append(temp_arr)\n",
    "\n",
    "    sequences = generated_indices.cpu().detach().numpy().tolist()\n",
    "    extracted_indices = []\n",
    "    for batch_idx, seq in enumerate(sequences):\n",
    "        returned_indices = find_sub_indices(seq, encoded_actual_texts[batch_idx])\n",
    "        extracted_indices.append(returned_indices)\n",
    "\n",
    "    data_extracted_indices.append(extracted_indices)\n",
    "    data_output_states.append(outputs.hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "27c07e70-ee66-4a8c-ad2f-00173109915e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(len(data_extracted_indices))\n",
    "print(len(data_output_states))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "6490f769-edce-4911-b651-00548c121300",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_example_hidden_states = data_output_states[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "e5b663ae-a71b-4249-bf98-7972995a3f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n"
     ]
    }
   ],
   "source": [
    "print(len(first_example_hidden_states))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "e6398dce-7fa6-45f4-8ece-f0e7f0a0746e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "print(len(first_example_hidden_states[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "27dfe17b-c00b-4572-951f-ad6826f25543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "print(len(first_example_hidden_states[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "5058719a-29e6-4941-aba2-41d4b2e16964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 175, 4096])\n"
     ]
    }
   ],
   "source": [
    "print(first_example_hidden_states[0][-1].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "e2faf02a-f9a9-457d-8989-36e325e8911d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 4096])\n"
     ]
    }
   ],
   "source": [
    "print(first_example_hidden_states[1][-1].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "8633e3a3-0fa5-4af5-b462-78a0daf69e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 4096])\n"
     ]
    }
   ],
   "source": [
    "print(first_example_hidden_states[2][-1].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "3e01db20-d99b-4b66-ae3e-07baf32b3d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 4096])\n"
     ]
    }
   ],
   "source": [
    "print(first_example_hidden_states[-1][-1].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "33d921d3-8382-410a-95c7-da78b354c907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17], [19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], [36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51], [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69], [71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88]]\n"
     ]
    }
   ],
   "source": [
    "# Indices for the input and paraphrases of the first example.\n",
    "print(data_extracted_indices[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "8d9befdd-376c-4b40-b5f4-739c111bd16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "representations = []\n",
    "for example_idx in range(4):\n",
    "    example_indices = data_extracted_indices[example_idx][0]\n",
    "    example_hidden_states = data_output_states[example_idx]\n",
    "    example_representations = {i: [] for i in range(5)}\n",
    "    for rep_idx in range(5):\n",
    "        rep_example_indices = example_indices[rep_idx]\n",
    "        rep_states = []\n",
    "        for layer_idx in range(33):\n",
    "            layer_rep = []\n",
    "            for each_idx in rep_example_indices:\n",
    "                each_idx_layer_state = example_hidden_states[each_idx][layer_idx]\n",
    "                layer_rep.append(each_idx_layer_state[0][0])\n",
    "            layer_rep_state = sum(layer_rep) / len(layer_rep)\n",
    "            example_representations[rep_idx].append(layer_rep_state)\n",
    "    representations.append(example_representations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "30bf222e-b9d0-452a-80fd-1cf886dff2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(len(representations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "2cb47259-d5da-4c6e-8388-7a1847318c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "print(len(representations[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "86e3f307-6b25-4e1e-a92a-6b3bfba910b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "print(len(representations[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "9a0be713-5a72-432e-ab58-6034d9d89020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "print(len(representations[0][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "8241ef72-e869-40d2-a444-ae2dfaaeeae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "print(len(representations[0][3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "9289efd0-8217-442a-b8ae-5e8d6c8cb176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "print(len(representations[0][4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "45d11f3e-caac-4dee-a9a0-0f428423d2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.3535,  0.3672, -0.8906,  ...,  0.2949, -0.6094, -1.0234],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "source": [
    "print(representations[0][4][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "e9d8d69e-7ceb-49de-92e8-e3aa1b0bfc8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.4609,  1.1797, -0.4668,  ..., -0.3926, -0.9453,  0.7227],\n",
       "       device='cuda:0', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "representations[0][0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "8edbf25c-aa18-46ee-8353-fa9c8389b1a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.1016, -0.8945, -0.3594,  ...,  0.0078, -1.7891, -0.6641],\n",
       "       device='cuda:0', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "representations[3][0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "2081df65-ace0-4c2d-ab4e-ea880695fb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "cos = torch.nn.CosineSimilarity(dim=0, eps=1e-08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "97a9e4f7-998e-4afd-bba5-24c7b4d93ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_representations = []\n",
    "for example_idx in range(4):\n",
    "    example_representations = representations[example_idx]\n",
    "    new_averaged_representations = []\n",
    "    for layer_id in range(33):\n",
    "        averaged_rep_per_layer = []\n",
    "        for para_id in range(5):\n",
    "            rep_per_layer = example_representations[para_id][layer_id]\n",
    "            averaged_rep_per_layer.append(rep_per_layer)\n",
    "        avg_rep = sum(averaged_rep_per_layer) / len(averaged_rep_per_layer)\n",
    "        new_averaged_representations.append(avg_rep)\n",
    "    average_representations.append(new_averaged_representations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "2b7fca62-aa7e-4893-9092-cf1023685c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0.9805, device='cuda:0', dtype=torch.bfloat16)\n",
      "1 tensor(0.9844, device='cuda:0', dtype=torch.bfloat16)\n",
      "2 tensor(0.9844, device='cuda:0', dtype=torch.bfloat16)\n",
      "3 tensor(0.9922, device='cuda:0', dtype=torch.bfloat16)\n",
      "4 tensor(0.9922, device='cuda:0', dtype=torch.bfloat16)\n",
      "5 tensor(0.9922, device='cuda:0', dtype=torch.bfloat16)\n",
      "6 tensor(0.9844, device='cuda:0', dtype=torch.bfloat16)\n",
      "7 tensor(0.9844, device='cuda:0', dtype=torch.bfloat16)\n",
      "8 tensor(0.9766, device='cuda:0', dtype=torch.bfloat16)\n",
      "9 tensor(0.9766, device='cuda:0', dtype=torch.bfloat16)\n",
      "10 tensor(0.9727, device='cuda:0', dtype=torch.bfloat16)\n",
      "11 tensor(0.9688, device='cuda:0', dtype=torch.bfloat16)\n",
      "12 tensor(0.9727, device='cuda:0', dtype=torch.bfloat16)\n",
      "13 tensor(0.9492, device='cuda:0', dtype=torch.bfloat16)\n",
      "14 tensor(0.9492, device='cuda:0', dtype=torch.bfloat16)\n",
      "15 tensor(0.9492, device='cuda:0', dtype=torch.bfloat16)\n",
      "16 tensor(0.9414, device='cuda:0', dtype=torch.bfloat16)\n",
      "17 tensor(0.9570, device='cuda:0', dtype=torch.bfloat16)\n",
      "18 tensor(0.9609, device='cuda:0', dtype=torch.bfloat16)\n",
      "19 tensor(0.9688, device='cuda:0', dtype=torch.bfloat16)\n",
      "20 tensor(0.9688, device='cuda:0', dtype=torch.bfloat16)\n",
      "21 tensor(0.9688, device='cuda:0', dtype=torch.bfloat16)\n",
      "22 tensor(0.9609, device='cuda:0', dtype=torch.bfloat16)\n",
      "23 tensor(0.9727, device='cuda:0', dtype=torch.bfloat16)\n",
      "24 tensor(0.9727, device='cuda:0', dtype=torch.bfloat16)\n",
      "25 tensor(0.9727, device='cuda:0', dtype=torch.bfloat16)\n",
      "26 tensor(0.9805, device='cuda:0', dtype=torch.bfloat16)\n",
      "27 tensor(0.9844, device='cuda:0', dtype=torch.bfloat16)\n",
      "28 tensor(0.9844, device='cuda:0', dtype=torch.bfloat16)\n",
      "29 tensor(0.9844, device='cuda:0', dtype=torch.bfloat16)\n",
      "30 tensor(0.9883, device='cuda:0', dtype=torch.bfloat16)\n",
      "31 tensor(0.9922, device='cuda:0', dtype=torch.bfloat16)\n",
      "32 tensor(0.9648, device='cuda:0', dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "source": [
    "for layer_id in range(33):\n",
    "    first_example_reps = average_representations[0][layer_id]\n",
    "    third_example_reps = average_representations[2][layer_id]\n",
    "    print(layer_id, cos(first_example_reps, third_example_reps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "47bd29ea-22df-405b-b63b-1087c5eddd45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0.7969, device='cuda:0', dtype=torch.bfloat16)\n",
      "1 tensor(0.8828, device='cuda:0', dtype=torch.bfloat16)\n",
      "2 tensor(0.8477, device='cuda:0', dtype=torch.bfloat16)\n",
      "3 tensor(0.8867, device='cuda:0', dtype=torch.bfloat16)\n",
      "4 tensor(0.8711, device='cuda:0', dtype=torch.bfloat16)\n",
      "5 tensor(0.8398, device='cuda:0', dtype=torch.bfloat16)\n",
      "6 tensor(0.8516, device='cuda:0', dtype=torch.bfloat16)\n",
      "7 tensor(0.8477, device='cuda:0', dtype=torch.bfloat16)\n",
      "8 tensor(0.8242, device='cuda:0', dtype=torch.bfloat16)\n",
      "9 tensor(0.8359, device='cuda:0', dtype=torch.bfloat16)\n",
      "10 tensor(0.8516, device='cuda:0', dtype=torch.bfloat16)\n",
      "11 tensor(0.8555, device='cuda:0', dtype=torch.bfloat16)\n",
      "12 tensor(0.8828, device='cuda:0', dtype=torch.bfloat16)\n",
      "13 tensor(0.8555, device='cuda:0', dtype=torch.bfloat16)\n",
      "14 tensor(0.8398, device='cuda:0', dtype=torch.bfloat16)\n",
      "15 tensor(0.8477, device='cuda:0', dtype=torch.bfloat16)\n",
      "16 tensor(0.8047, device='cuda:0', dtype=torch.bfloat16)\n",
      "17 tensor(0.8047, device='cuda:0', dtype=torch.bfloat16)\n",
      "18 tensor(0.7969, device='cuda:0', dtype=torch.bfloat16)\n",
      "19 tensor(0.8164, device='cuda:0', dtype=torch.bfloat16)\n",
      "20 tensor(0.8164, device='cuda:0', dtype=torch.bfloat16)\n",
      "21 tensor(0.8047, device='cuda:0', dtype=torch.bfloat16)\n",
      "22 tensor(0.8242, device='cuda:0', dtype=torch.bfloat16)\n",
      "23 tensor(0.8281, device='cuda:0', dtype=torch.bfloat16)\n",
      "24 tensor(0.8477, device='cuda:0', dtype=torch.bfloat16)\n",
      "25 tensor(0.8633, device='cuda:0', dtype=torch.bfloat16)\n",
      "26 tensor(0.8594, device='cuda:0', dtype=torch.bfloat16)\n",
      "27 tensor(0.8711, device='cuda:0', dtype=torch.bfloat16)\n",
      "28 tensor(0.8789, device='cuda:0', dtype=torch.bfloat16)\n",
      "29 tensor(0.8906, device='cuda:0', dtype=torch.bfloat16)\n",
      "30 tensor(0.8672, device='cuda:0', dtype=torch.bfloat16)\n",
      "31 tensor(0.8633, device='cuda:0', dtype=torch.bfloat16)\n",
      "32 tensor(0.6016, device='cuda:0', dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "source": [
    "for layer_id in range(33):\n",
    "    second_example_reps = average_representations[1][layer_id]\n",
    "    forth_example_reps = average_representations[3][layer_id]\n",
    "    print(layer_id, cos(second_example_reps, forth_example_reps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45074bf7-a54f-432a-af9b-a07fbe1fecff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.metrics import QAMetricModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8768ced-b71f-493f-b3ca-35d5ec7dc4d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['plate is to the right of the knife.', 'Yesterday was tough day.', 'knife is to the left of the plate.', 'The capital is Toronto.']\n"
     ]
    }
   ],
   "source": [
    "reference_inputs = [[\"knife is to the left of the plate.\"], [\"The capital is Toronto.\"]]\n",
    "\n",
    "candidate_inputs = [[\"plate is to the right of the knife.\"], [\"Yesterday was tough day.\"]]\n",
    "\n",
    "references_flattened = []\n",
    "for ref_sub_arr in reference_inputs:\n",
    "    references_flattened.extend(ref_sub_arr)\n",
    "\n",
    "candidates_flattened = []\n",
    "for cand_sub_arr in candidate_inputs:\n",
    "    candidates_flattened.extend(cand_sub_arr)\n",
    "\n",
    "all_data = []\n",
    "all_data.extend(candidates_flattened)\n",
    "all_data.extend(references_flattened)\n",
    "\n",
    "print(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "faba4de4-dde4-415b-9799-74ab037b0e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/fs01/home/snajafi/codes/llm-research/llm-env/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "qa_metric_model = QAMetricModel(device=\"cuda:0\", batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f213e87c-b618-456f-bc47-0bcb99028d4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9192931056022644"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_metric_model.compute_metric([\"plate is to the right of the knife.\"], [[\"knife is to the left of the plate.\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63ad507-23f5-4cf8-bf0a-463c29013d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_metric_model.compute_metric(['Yesterday was tough day.'],\n",
    "                              [[The capital is Toronto.']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c439fd0-8ba8-4007-8c24-9a48bdf60a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['assistant\\n\\nHere are five supporting facts to answer the question:\\n\\nFact 1: The passage mentions that the Grotto at Notre Dame is a replica of the grotto at Lourdes, France.\\n\\nFact 2: The passage states that the Virgin Mary reputedly appeared to someone at Lourdes, France in 1858.\\n\\nFact 3: The passage does not mention the name of the person to whom the Virgin Mary appeared, but it does mention the location (Lourdes, France) and the year (1858).\\n\\nFact 4: The passage does not provide any information about the person to whom the Virgin Mary appeared, but it does mention that the apparition was witnessed by Saint Bernadette Soubirous.\\n\\nFact 5: Therefore, it can be concluded that the Virgin Mary allegedly appeared to Saint Bernadette Soubirous in 1858 in Lourdes, France.']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "from src.llama3 import llama3_input_template, llama3_instruction_llama\n",
    "\n",
    "instruction = (\n",
    "    \"\"\"I will give you a passage and a question. To answer the question, I want you to generate five supporting facts.\"\"\"\n",
    ")\n",
    "\n",
    "llama3_inst = llama3_instruction_llama.format(instruction=instruction)\n",
    "\n",
    "data = \"\"\"Passage: Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.\n",
    "Question: To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?\n",
    "Answer: Let's think step by step within five supporting facts.\n",
    "\"\"\"\n",
    "\n",
    "llama3_inputs = [f'{llama3_inst}{llama3_input_template.format(input=f\"{data}\")}']\n",
    "\n",
    "input_data = model.prepare_text_for_inference(llama3_inputs)\n",
    "dataset = DictDataset(input_data)\n",
    "data_loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "for data in data_loader:\n",
    "    answers, log_ps, outputs = model.generation_pass(data)\n",
    "    print(answers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
