{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39997174-f08f-477f-8878-e2290d99d336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook to send and run the llama3 predictions.\n",
    "import csv\n",
    "import io\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from src.llm_client import parallel_generator\n",
    "from src.utils.data_utility import process_squadv2_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75d056cf-8396-4bf6-9f4c-f0e50c859786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llama3 chat templates.\n",
    "instruction_template = \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\n{instruction} <|eot_id|>\"\n",
    "input_template = \"<|start_header_id|>user<|end_header_id|>\\n\\n{input} <|eot_id|>\"\n",
    "output_template = \"<|start_header_id|>assistant<|end_header_id|>\\n\\n{output} <|eot_id|>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75bc2cb2-6878-4f79-b97f-83e83b9df6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model name and server address\n",
    "model_name = \"/model-weights/Meta-Llama-3-8B-Instruct\"\n",
    "server_address = \"http://172.17.8.9:51813/v1\"\n",
    "output_path = \"/scratch/ssd004/scratch/snajafi/checkpoints/llama3-predictions\"\n",
    "# experiment_type = \"normal_no_icl\"\n",
    "experiment_type = \"explanation_no_icl\"\n",
    "# experiment_type = \"normal_icl\"\n",
    "# experiment_type = \"explanation_icl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aef37b59-8245-43b4-bde4-3115177fa5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"../data/0.1-shot-datasets/squad/original_validation.tsv\"\n",
    "output_file = f\"squadv2_predictions_original_validation.{experiment_type}.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "086f6297-8bd0-4e65-8958-fb471dd0992d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11873\n",
      "11873\n",
      "11873\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "This task is about writing a correct answer for the reading comprehension task. Based on the information provided in a given passage, you should identify the shortest continuous text span from the passage that serves as an answer to the given question. Avoid answers that are incorrect or have incomplete justification. Generate your explanations and thought process before generating the final answer. If you cannot find the answer from the passage for the given question, then generate the <no_answer> tag as the final answer. <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Passage: The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III of West Francia. Through generations of assimilation and mixing with the native Frankish and Roman-Gaulish populations, their descendants would gradually merge with the Carolingian-based cultures of West Francia. The distinct cultural and ethnic identity of the Normans emerged initially in the first half of the 10th century, and it continued to evolve over the succeeding centuries.\n",
      "Question: In what country is Normandy located?\n",
      "Explanations and Thought Process and Final Answer:  <|eot_id|>\n",
      "1\n",
      "France\n"
     ]
    }
   ],
   "source": [
    "# read the input data.\n",
    "squad_inputs, squad_ids, _, gold_outputs = process_squadv2_dataset(\n",
    "    input_file, experiment_type, instruction_template, input_template, output_template\n",
    ")\n",
    "\n",
    "print(len(squad_inputs))\n",
    "print(len(squad_ids))\n",
    "# print(len(squad_outputs))\n",
    "print(len(gold_outputs))\n",
    "\n",
    "print(squad_inputs[0])\n",
    "print(squad_ids[0])\n",
    "# print(squad_outputs[0])\n",
    "print(gold_outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed2af309-ff49-497d-a4e6-c78d729aa9c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/fs01/home/snajafi/codes/llm-research/src/llm_client.py:153\u001b[0m, in \u001b[0;36mparallel_generator\u001b[0;34m(server_url, model_name, inputs, num_threads, max_new_tokens, max_retries, seconds_between_retries, request_batch_size, stop_token_ids, top_p, temperature, logprobs, seed)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m futures:\n\u001b[0;32m--> 153\u001b[0m         final_responses\u001b[38;5;241m.\u001b[39mextend(\u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m final_responses\n",
      "File \u001b[0;32m~/miniconda3/envs/llm-env/lib/python3.11/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 451\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/miniconda3/envs/llm-env/lib/python3.11/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m     \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m headers \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpotential_answer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction_score\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrow_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgold_answer\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      5\u001b[0m writer\u001b[38;5;241m.\u001b[39mwriterow(headers)\n\u001b[0;32m----> 6\u001b[0m responses \u001b[38;5;241m=\u001b[39m \u001b[43mparallel_generator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserver_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msquad_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseconds_between_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinished prediction in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_time\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/fs01/home/snajafi/codes/llm-research/src/llm_client.py:131\u001b[0m, in \u001b[0;36mparallel_generator\u001b[0;34m(server_url, model_name, inputs, num_threads, max_new_tokens, max_retries, seconds_between_retries, request_batch_size, stop_token_ids, top_p, temperature, logprobs, seed)\u001b[0m\n\u001b[1;32m    129\u001b[0m     num_threads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(inputs)\n\u001b[1;32m    130\u001b[0m     chunk_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 131\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mThreadPoolExecutor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_threads\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexecutor\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mthread_i\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnum_threads\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/llm-env/lib/python3.11/concurrent/futures/_base.py:647\u001b[0m, in \u001b[0;36mExecutor.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[0;32m--> 647\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshutdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/llm-env/lib/python3.11/concurrent/futures/thread.py:235\u001b[0m, in \u001b[0;36mThreadPoolExecutor.shutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads:\n\u001b[0;32m--> 235\u001b[0m         \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/llm-env/lib/python3.11/threading.py:1112\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1109\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1112\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1113\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1114\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1116\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/llm-env/lib/python3.11/threading.py:1132\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1133\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1134\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.perf_counter()\n",
    "with io.open(f\"{output_path}/{output_file}\", mode=\"w\", encoding=\"utf-8\") as out_fp:\n",
    "    writer = csv.writer(out_fp, quotechar='\"', quoting=csv.QUOTE_ALL)\n",
    "    headers = [\"potential_answer\", \"prediction_score\", \"row_id\", \"gold_answer\"]\n",
    "    writer.writerow(headers)\n",
    "    responses = parallel_generator(\n",
    "        server_url=server_address,\n",
    "        model_name=model_name,\n",
    "        inputs=squad_inputs,\n",
    "        num_threads=10,\n",
    "        max_new_tokens=256,\n",
    "        max_retries=3,\n",
    "        seconds_between_retries=5,\n",
    "        request_batch_size=16,\n",
    "    )\n",
    "    end_time = time.perf_counter()\n",
    "    print(f\"Finished prediction in {end_time - start_time} seconds!\")\n",
    "    for idx, response in enumerate(responses):\n",
    "        to_write = [response.text, np.mean(response.logprobs.token_logprobs), squad_ids[idx], gold_outputs[idx]]\n",
    "        writer.writerow(to_write)\n",
    "\n",
    "print(f\"Finished i/o in {time.perf_counter() - end_time} seconds!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8268f77e-cad5-4538-a99e-2951c3ae3d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_types = [\"normal_icl\", \"explanation_icl\"]\n",
    "for experiment_type in experiment_types:\n",
    "    output_file = f\"squadv2_predictions_original_validation.{experiment_type}.csv\"\n",
    "    # read the input data.\n",
    "    squad_inputs, squad_ids, _, gold_outputs = process_squadv2_dataset(\n",
    "        input_file, experiment_type, instruction_template, input_template, output_template\n",
    "    )\n",
    "    print(len(squad_inputs))\n",
    "    print(len(squad_ids))\n",
    "    print(len(gold_outputs))\n",
    "    print(squad_inputs[0])\n",
    "    print(squad_ids[0])\n",
    "    print(gold_outputs[0])\n",
    "    start_time = time.perf_counter()\n",
    "    with io.open(f\"{output_path}/{output_file}\", mode=\"w\", encoding=\"utf-8\") as out_fp:\n",
    "        writer = csv.writer(out_fp, quotechar='\"', quoting=csv.QUOTE_ALL)\n",
    "        headers = [\"potential_answer\", \"prediction_score\", \"row_id\", \"gold_answer\"]\n",
    "        writer.writerow(headers)\n",
    "        responses = parallel_generator(\n",
    "            server_url=server_address,\n",
    "            model_name=model_name,\n",
    "            inputs=squad_inputs,\n",
    "            num_threads=4,\n",
    "            max_new_tokens=256,\n",
    "            max_retries=3,\n",
    "            seconds_between_retries=5,\n",
    "            request_batch_size=16,\n",
    "        )\n",
    "        end_time = time.perf_counter()\n",
    "        print(f\"Finished prediction in {end_time - start_time} seconds!\")\n",
    "        for idx, response in enumerate(responses):\n",
    "            to_write = [response.text, np.mean(response.logprobs.token_logprobs), squad_ids[idx], gold_outputs[idx]]\n",
    "            writer.writerow(to_write)\n",
    "\n",
    "    print(f\"Finished i/o in {time.perf_counter() - end_time} seconds!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30602b60-101f-4c25-ac63-05c56c0918a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
