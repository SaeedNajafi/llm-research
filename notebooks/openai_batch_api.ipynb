{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d5963237-97e3-4494-8348-650515e35f8e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "import csv\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "from typing import Any, Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "\n",
    "from src.squadv2_instructions import explanation_icl_input, explanation_instruction, normal_icl_input, normal_instruction\n",
    "from src.utils.general_utils import white_space_fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "43ec077d-5d8c-4805-bb09-ed11e19d2a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8771b1ee-c800-4e3b-955d-0fdf09da19a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_squadv2_dataset(\n",
    "    file_name: str, experiment_type: str, instruction_template: str, input_template: str, output_template: str\n",
    ") -> Tuple[List[str], List[str], List[str], List[str], str]:\n",
    "    \"\"\"Read and pre-process the squadv2 dataset for my application.\"\"\"\n",
    "\n",
    "    dataset = pd.read_csv(file_name, sep=\"\\t\").to_dict(orient=\"records\")\n",
    "    if experiment_type == \"normal_no_icl\":\n",
    "        instruction = normal_instruction\n",
    "    elif experiment_type == \"explanation_no_icl\":\n",
    "        instruction = explanation_instruction\n",
    "\n",
    "    formed_instruction = instruction_template.format(instruction=instruction)\n",
    "\n",
    "    next_example_number = 11 if \"_no_\" not in experiment_type else -1\n",
    "    squad_inputs = []\n",
    "    squad_outputs = []\n",
    "    gold_outputs = []\n",
    "    squad_ids = []\n",
    "    idx = 0\n",
    "    for row in dataset:\n",
    "        idx += 1\n",
    "        context = row[\"context\"]\n",
    "        question = row[\"question\"]\n",
    "        gold_answers = ast.literal_eval(row[\"answers\"])\n",
    "        context = white_space_fix(context)\n",
    "        question = white_space_fix(question)\n",
    "        if experiment_type == \"normal_no_icl\":\n",
    "            user_final_message = f\"Passage: {context}\"\n",
    "            user_final_message += f\"\\nQuestion: {question}\"\n",
    "            user_final_message += \"\\nFinal Answer: \"\n",
    "        elif experiment_type == \"explanation_no_icl\":\n",
    "            user_final_message = f\"Passage: {context}\"\n",
    "            user_final_message += f\"\\nQuestion: {question}\"\n",
    "            user_final_message += \"\\nExplanations and Thought Process and Final Answer: \"\n",
    "        formed_input = input_template.format(input=user_final_message)\n",
    "        squad_input = formed_input\n",
    "        squad_inputs.append(squad_input)\n",
    "        squad_ids.append(str(idx))\n",
    "\n",
    "        gold_outputs.append(\"_@_\".join(gold_answers))\n",
    "        gold_answer = random.choice(gold_answers)\n",
    "        if experiment_type == \"normal_no_icl\":\n",
    "            squad_output = output_template.format(output=f\"Final Answer: {gold_answer}\")\n",
    "            squad_outputs.append(squad_output)\n",
    "    return squad_inputs, squad_ids, squad_outputs, gold_outputs, formed_instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a259ad53-2c76-4147-b572-e4d238cf5849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4037\n",
      "4037\n",
      "4037\n",
      "<s> Passage: The system of bureaucracy created by Kublai Khan reflected various cultures in the empire, including that of the Han Chinese, Khitans, Jurchens, Mongols, and Tibetan Buddhists. While the official terminology of the institutions may indicate the government structure was almost purely that of native Chinese dynasties, the Yuan bureaucracy actually consisted of a mix of elements from different cultures. The Chinese-style elements of the bureaucracy mainly came from the native Tang, Song, as well as Khitan Liao and Jurchen Jin dynasties. Chinese advisers such as Liu Bingzhong and Yao Shu gave strong influence to Kublai's early court, and the central government administration was established within the first decade of Kublai's reign. This government adopted the traditional Chinese tripartite division of authority among civil, military, and censorial offices, including the Central Secretariat (Zhongshu Sheng) to manage civil affairs, the Privy Council (Chinese: 樞密院) to manage military affairs, and the Censorate to conduct internal surveillance and inspection. The actual functions of both central and local government institutions, however, showed a major overlap between the civil and military jurisdictions, due to the Mongol traditional reliance on military institutions and offices as the core of governance. Nevertheless, such a civilian bureaucracy, with the Central Secretariat as the top institution that was (directly or indirectly) responsible for most other governmental agencies (such as the traditional Chinese-style Six Ministries), was created in China. At various times another central government institution called the Department of State Affairs (Shangshu Sheng) that mainly dealt with finance was established (such as during the reign of Külüg Khan or Emperor Wuzong), but was usually abandoned shortly afterwards.\n",
      "Question: What kind of division of power did Kublai's government have?\n",
      "Explanations and Thought Process and Final Answer:  </s>\n",
      "1\n",
      "tripartite division_@_tripartite\n",
      "<s> You will output a json object containing the following information:\n",
      "This task is about writing a correct answer for the reading comprehension task. Based on the information provided in a given passage, you should identify the shortest continuous text span from the passage that serves as an answer to the given question. Avoid answers that are incorrect or have incomplete justification. Generate your explanations and thought process before generating the final answer. If you cannot find the answer from the passage for the given question, then generate the <no_answer> tag as the final answer. </s>\n"
     ]
    }
   ],
   "source": [
    "# my gpt4-omini chat templates.\n",
    "instruction_template = \"<s> You will output a json object containing the following information:\\n{instruction} </s>\"\n",
    "input_template = \"<s> {input} </s>\"\n",
    "output_template = \"<s> {output} </s>\"\n",
    "input_file = \"../data/0.1-shot-datasets/squad/original_validation_part3.tsv\"\n",
    "experiment_type = \"explanation_no_icl\"\n",
    "# read the input data.\n",
    "squad_inputs, squad_ids, _, gold_outputs, formed_instruction = process_squadv2_dataset(\n",
    "    input_file, experiment_type, instruction_template, input_template, output_template\n",
    ")\n",
    "\n",
    "row_id_to_answer_mapper = {row_id: gold_outputs[idx] for idx, row_id in enumerate(squad_ids)}\n",
    "# print(row_id_to_answer_mapper)\n",
    "print(len(squad_inputs))\n",
    "print(len(squad_ids))\n",
    "print(len(gold_outputs))\n",
    "print(squad_inputs[0])\n",
    "print(squad_ids[0])\n",
    "print(gold_outputs[0])\n",
    "print(formed_instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "787c3a0e-951f-4a0a-9a3a-6ff5be1d909e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = []\n",
    "\n",
    "for index, squad_input in enumerate(squad_inputs):\n",
    "    task = {\n",
    "        \"custom_id\": f\"task-squadv2-{experiment_type}-{squad_ids[index]}\",\n",
    "        \"method\": \"POST\",\n",
    "        \"url\": \"/v1/chat/completions\",\n",
    "        \"body\": {\n",
    "            \"model\": \"gpt-4o-mini\",\n",
    "            \"temperature\": 0.001,\n",
    "            \"top_p\": 0.9,\n",
    "            \"n\": 1,\n",
    "            \"max_tokens\": 256,\n",
    "            \"seed\": 42,\n",
    "            \"logprobs\": True,\n",
    "            \"stop\": [\"</s>\"],\n",
    "            \"response_format\": {\"type\": \"json_object\"},\n",
    "            \"messages\": [{\"role\": \"system\", \"content\": formed_instruction}, {\"role\": \"user\", \"content\": squad_input}],\n",
    "        },\n",
    "    }\n",
    "    tasks.append(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3d20307c-82af-4f86-a5f9-d05149874de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'custom_id': 'task-squadv2-explanation_no_icl-11', 'method': 'POST', 'url': '/v1/chat/completions', 'body': {'model': 'gpt-4o-mini', 'temperature': 0.001, 'top_p': 0.9, 'n': 1, 'max_tokens': 256, 'seed': 42, 'logprobs': True, 'stop': ['</s>'], 'response_format': {'type': 'json_object'}, 'messages': [{'role': 'system', 'content': '<s> You will output a json object containing the following information:\\nThis task is about writing a correct answer for the reading comprehension task. Based on the information provided in a given passage, you should identify the shortest continuous text span from the passage that serves as an answer to the given question. Avoid answers that are incorrect or have incomplete justification. Generate your explanations and thought process before generating the final answer. If you cannot find the answer from the passage for the given question, then generate the <no_answer> tag as the final answer. </s>'}, {'role': 'user', 'content': '<s> Passage: While the existence of these central government departments and the Six Ministries (which had been introduced since the Sui and Tang dynasties) gave a Sinicized image in the Yuan administration, the actual functions of these ministries also reflected how Mongolian priorities and policies reshaped and redirected those institutions. For example, the authority of the Yuan legal system, the Ministry of Justice, did not extend to legal cases involving Mongols and Semuren, who had separate courts of justice. Cases involving members of more than one ethnic group were decided by a mixed board consisting of Chinese and Mongols. Another example was the insignificance of the Ministry of War compared with native Chinese dynasties, as the real military authority in Yuan times resided in the Privy Council.\\nQuestion: Who had military control during the Yuan?\\nExplanations and Thought Process and Final Answer:  </s>'}]}}\n"
     ]
    }
   ],
   "source": [
    "print(tasks[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "57cab63d-9468-4510-bda5-9887790be14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_data_01-shot-datasets_squad_original_validation_part3\n"
     ]
    }
   ],
   "source": [
    "file_id = input_file.rstrip(\".tsv\").replace(\".\", \"\").replace(\"/\", \"_\")\n",
    "print(file_id)\n",
    "file_name = f\"../data/openai_batch_squadv2.{experiment_type}.{file_id}.jsonl\"\n",
    "\n",
    "with open(file_name, \"w\") as file:\n",
    "    for obj in tasks:\n",
    "        file.write(json.dumps(obj) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7da6db6d-f8ce-4895-a610-14b8f6c58905",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_file = client.files.create(file=open(file_name, \"rb\"), purpose=\"batch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "818cf448-35d1-4415-90c1-a5c1fca0b726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-TexCWKicXEGGeHQZGOpAOtwA', bytes=7747679, created_at=1721833381, filename='openai_batch_squadv2.explanation_no_icl._data_01-shot-datasets_squad_original_validation_part3.jsonl', object='file', purpose='batch', status='processed', status_details=None)\n"
     ]
    }
   ],
   "source": [
    "print(batch_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3c4dfb20-84b6-498b-acc0-afa1c788d7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_job = client.batches.create(input_file_id=batch_file.id, endpoint=\"/v1/chat/completions\", completion_window=\"24h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3c9bf0b3-c079-4172-9534-43ea50b6d166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(id='batch_IX22tvuT6KqkIGNQXwoceRqE', completion_window='24h', created_at=1721833384, endpoint='/v1/chat/completions', input_file_id='file-TexCWKicXEGGeHQZGOpAOtwA', object='batch', status='in_progress', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1721919784, failed_at=None, finalizing_at=None, in_progress_at=1721833388, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=4037))\n"
     ]
    }
   ],
   "source": [
    "batch_job = client.batches.retrieve(batch_job.id)\n",
    "print(batch_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cb066db0-1f50-4342-800e-bd48a54a8408",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected a non-empty value for `file_id` but received None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m result_file_id \u001b[38;5;241m=\u001b[39m batch_job\u001b[38;5;241m.\u001b[39moutput_file_id\n\u001b[0;32m----> 2\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult_file_id\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcontent\n",
      "File \u001b[0;32m~/miniconda3/envs/llm-env/lib/python3.11/site-packages/openai/resources/files.py:256\u001b[0m, in \u001b[0;36mFiles.content\u001b[0;34m(self, file_id, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;124;03mReturns the contents of the specified file.\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;124;03m  timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m file_id:\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected a non-empty value for `file_id` but received \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_id\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    257\u001b[0m extra_headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccept\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/binary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(extra_headers \u001b[38;5;129;01mor\u001b[39;00m {})}\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get(\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/files/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/content\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    260\u001b[0m     options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    263\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39m_legacy_response\u001b[38;5;241m.\u001b[39mHttpxBinaryResponseContent,\n\u001b[1;32m    264\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: Expected a non-empty value for `file_id` but received None"
     ]
    }
   ],
   "source": [
    "result_file_id = batch_job.output_file_id\n",
    "result = client.files.content(result_file_id).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ce8eb532-b90b-480f-87f2-af7990409fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file_name = f\"../data/openai_batch_squadv2.{experiment_type}.{file_id}.results.jsonl\"\n",
    "\n",
    "with open(result_file_name, \"wb\") as file:\n",
    "    file.write(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "18e12bd5-9fff-4e5a-b03f-40e5d2630ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data and save in the correct format.\n",
    "# Loading data from saved file\n",
    "results = []\n",
    "with open(result_file_name, \"r\") as file:\n",
    "    for line in file:\n",
    "        # Parsing the JSON string into a dict and appending to the list of results\n",
    "        json_object = json.loads(line.strip())\n",
    "        results.append(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "40fc414c-b58b-4732-81b3-c01b1b75b5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = results[0][\"response\"][\"body\"][\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "85c1f52a-e54b-4241-a2f0-3d87aab90dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\"explanation\": \"The passage discusses various ctenophores and their feeding habits. It specifically mentions that members of the genus Haeckelia incorporate nematocysts from jellyfish into their tentacles. However, it does not provide information about Pleurobrachia incorporating anything into their tentacles. Therefore, since the passage does not mention what Pleurobrachia incorporates into their tentacles, the answer is <no_answer>.\", \"final_answer\": \"<no_answer>\"}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1e89c5b9-3c90-4fb3-8e3d-1a63639a9d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\"explanation\": \"The passage states that Bill Aken made his first TV appearance playing guitar on the old country-western show at The Fresno Barn. This directly answers the question about the show on which he made his television debut.\", \"final_answer\": \"The Fresno Barn\"}\n"
     ]
    }
   ],
   "source": [
    "print(results[100][\"response\"][\"body\"][\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f2442919-abcc-4173-9c4b-97c69dea2d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.051726244, -0.8501451, -0.20377287, -0.004627003, -0.16022788, -1.6882126e-05, -0.5010923, -0.16225983, -0.63491267, -0.0046973573, -0.35759595, -5.6769813e-06, -0.004808061, -0.0014078516, -4.723352e-06, -0.00075542775, -0.018155914, -7.89631e-07, -0.17613155, -3.202099e-05, -0.0013624972, -0.2633079, -0.15924208, -4.365741e-06, -9.0883464e-07, 0.0, -6.704273e-07, -0.0010581758, -0.070725225, -3.1281633e-07, 0.0, -0.0007828262, -0.32516602, -0.88980186, -0.024234312, -5.6769813e-06, -0.000107715314, -0.4178135, -0.75545716, -0.019023685, -0.6219828, 0.0, -0.043739893, -0.016116716, -3.5313153e-06, -0.011317071, -3.1281633e-07, -0.30381453, -5.1808798e-05, -0.31489024, -2.9994528e-05, -1.4855664e-05, -3.1281633e-07, -0.07989125, -0.0019476758, 0.0, -0.0011714138]\n"
     ]
    }
   ],
   "source": [
    "print([each[\"logprob\"] for each in results[100][\"response\"][\"body\"][\"choices\"][0][\"logprobs\"][\"content\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c0367c28-5713-4264-9d77-043a3ee1f72f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task-squadv2-explanation_no_icl-101\n"
     ]
    }
   ],
   "source": [
    "print(results[100][\"custom_id\"].removeprefix(\"task-squadv2-normal_no_icl-\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5239a759-43cf-4640-baf1-fb8106c1a7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = (\n",
    "    f\"/scratch/ssd004/scratch/snajafi/gpt4-omini-predictions/original_validation_part2.{experiment_type}.gtp4-omini.tsv\"\n",
    ")\n",
    "\n",
    "with io.open(output_file, mode=\"w\", encoding=\"utf-8\") as out_fp:\n",
    "    writer = csv.writer(out_fp, quotechar='\"', quoting=csv.QUOTE_ALL)\n",
    "    headers = [\"potential_answer\", \"prediction_score\", \"row_id\", \"gold_answer\"]\n",
    "    writer.writerow(headers)\n",
    "    for idx, result in enumerate(results):\n",
    "        potential_answer = result[\"response\"][\"body\"][\"choices\"][0][\"message\"][\"content\"]\n",
    "        logprobs = [\n",
    "            each[\"logprob\"] for each in result[\"response\"][\"body\"][\"choices\"][0][\"logprobs\"][\"content\"] if each[\"logprob\"] > 0.0\n",
    "        ]\n",
    "        prediction_score = np.mean(logprobs) if len(logprobs) > 0 else 0.0\n",
    "        row_id = result[\"custom_id\"].removeprefix(f\"task-squadv2-{experiment_type}-\")\n",
    "        to_write = [potential_answer, prediction_score, row_id, row_id_to_answer_mapper[row_id]]\n",
    "        writer.writerow(to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea63521-179f-4a0d-9337-54da3ec7a91e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
